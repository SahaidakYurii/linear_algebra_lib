

##### ./CMakeLists.txt #####

cmake_minimum_required(VERSION 3.15)

set(PROJECT_NAME linear_algebra_lib)
project(${PROJECT_NAME} C CXX)

set(CMAKE_CXX_STANDARD 20)

if (NOT CMAKE_BUILD_TYPE)
	set(CMAKE_BUILD_TYPE Release)
endif()

include(FetchContent)

##########################################################
# Header-only library target
##########################################################
add_library(${PROJECT_NAME} INTERFACE)
target_include_directories(${PROJECT_NAME} INTERFACE include)

##########################################################
# Dependencies: Eigen (header-only)
##########################################################
FetchContent_Declare(
		eigen
		GIT_REPOSITORY https://gitlab.com/libeigen/eigen.git
		GIT_TAG 3.4.0
)
FetchContent_MakeAvailable(eigen)

##########################################################
# Main executables
##########################################################
add_executable(main
		src/main.cpp
)
target_link_libraries(main
		PRIVATE ${PROJECT_NAME}
)
target_include_directories(main PRIVATE ${eigen_SOURCE_DIR})

##########################################################
# Benchmark executables
##########################################################

add_executable(benchmark_runner
		benchmarks/benchmark.cpp
)
target_link_libraries(benchmark_runner
		PRIVATE ${PROJECT_NAME}
)
target_include_directories(benchmark_runner PRIVATE ${eigen_SOURCE_DIR})

add_executable(eigenvalue_benchmark
		benchmarks/eigenvalue_benchmark.cpp
)
target_link_libraries(eigenvalue_benchmark
		PRIVATE ${PROJECT_NAME}
)
target_include_directories(eigenvalue_benchmark PRIVATE ${eigen_SOURCE_DIR})

##########################################################
# GoogleTest: Unit test executable
##########################################################

FetchContent_Declare(
		gtest
		GIT_REPOSITORY https://github.com/google/googletest.git
		GIT_TAG release-1.12.1
)
FetchContent_MakeAvailable(gtest)

enable_testing()

add_executable(tests
		tests/test_vector.cpp
		tests/test_tenzor.cpp
		tests/test_matrix.cpp
		tests/test_squareMatrix.cpp
)

target_link_libraries(tests
		PRIVATE
		${PROJECT_NAME}
		gtest
		gtest_main
)

add_test(NAME unit_tests COMMAND tests)

##########################################################
# Optional: Install targets
##########################################################
install(TARGETS benchmark_runner eigenvalue_benchmark tests DESTINATION bin)


##### ./out.txt #####



##### ./src/main.cpp #####

#include <iostream>
#include "linalg.h"

int main(int argc, char* argv[]) {
    linalg::vector<linalg::vector<int>> jagged = {
        {1, 2},
        {3},
        {4, 5, 6}
    };

    linalg::matrix<int> m(jagged);

    std::cout << m.toString() << std::endl;
}


##### ./include/matrix.h #####

// This is a personal academic project. Dear PVS-Studio, please check it.
// PVS-Studio Static Code Analyzer for C, C++, C#, and Java: https://pvs-studio.com

#ifndef LINALG_MATRIX_H
#define LINALG_MATRIX_H
#include <sstream>

#include "tensor.h"

namespace linalg {
    template <typename T>
    class matrix : public tensor<T, 2> {
    protected:
        size_t rows_m, cols_m;

    public:
        matrix(const size_t rows, const size_t cols, vector<T> data = {})
            : tensor<T, 2>(data, rows, cols),
              rows_m(rows), cols_m(cols) {}

        explicit matrix(vector<vector<T>> vec2d)
            : tensor<T, 2>(
                vec2d.size(),
                vec2d.is_empty() ? 0 : std::max_element(vec2d.begin(), vec2d.end(),
                    [](const auto& a, const auto& b) {
                        return a.size() < b.size();
                    })->size()),
              rows_m(vec2d.size()),
              cols_m(vec2d.is_empty() ? 0 : std::max_element(vec2d.begin(), vec2d.end(),
                    [](const auto& a, const auto& b) {
                        return a.size() < b.size();
                    })->size())
        {
            for (size_t r = 0; r < rows_m; ++r) {
                std::copy(
                    vec2d[r].begin(),
                    vec2d[r].end(),
                    this->data_m.begin() + r * cols_m
                );

                if (vec2d[r].size() < cols_m) {
                    std::fill(
                        this->data_m.begin() + r * cols_m + vec2d[r].size(),
                        this->data_m.begin() + (r + 1) * cols_m,
                        T()
                    );
                }
            }
        }

        [[nodiscard]] size_t rows() const { return rows_m; }
        [[nodiscard]] size_t cols() const { return cols_m; }

        void reshape(const size_t rows, const size_t cols) {
            if (rows == rows_m && cols == cols_m) {
                return;
            }

            auto temp_data = vector<T>(rows * cols);

            for (size_t r = 0; r < (rows < rows_m ? rows : rows_m); r++) {
                for (size_t c = 0; c < (cols < cols_m ? cols : cols_m); c++) {
                    temp_data[r * cols + c] = this->data_m[r * cols_m + c];
                }
            }
            rows_m = rows; cols_m = cols;
            this->data_m = temp_data;
        }

        std::string toString() {
            std::stringstream ss;
            for (size_t r = 0; r < rows_m; r++) {
                for (size_t c = 0; c < cols_m; c++) {
                    ss << (*this)(r, c) << '\t';
                }
                ss << '\n';
            }

            return ss.str();
        }

        matrix<T> transpose() const{
            matrix<T> temp(cols_m, rows_m);
            for (size_t r = 0; r < rows_m; r++) {
                for (size_t c = 0; c < cols_m; c++) {
                    temp(c, r) = (*this)(r, c);
                }
            }

            return temp;
        }

        matrix<T>& operator*=(const matrix<T>& other) {
            if (this->cols_m != other.rows_m) {
                throw std::invalid_argument("Wrong dimensions of matrices");
            }

            size_t rows = this->rows_m, cols = other.cols_m;
            matrix<T> temp(rows, cols);

            for (size_t r = 0; r < rows; r++) {
                for (size_t c = 0; c < cols; c++) {
                    T sum{};
                    for (size_t i = 0; i < this->cols_m; i++) {
                        sum += (*this)(r, i) * other(i, c);
                    }
                    temp(r, c) = sum;
                }
            }
            *this = temp;
            return *this;
        }

        matrix<T>& operator*=(const T& scalar) {
            for (size_t i = 0; i < this->data_m.size(); ++i) {
                this->data_m[i] *= scalar;
            }
            return *this;
        }

        matrix<T> pinv() const;

        [[nodiscard]] size_t rank() const {
            matrix<T> temp(*this);
            const T EPS = static_cast<T>(1e-9);
            size_t rank = 0;
            size_t row = 0, col = 0;

            while (row < temp.rows_m && col < temp.cols_m) {
                // Find pivot
                size_t pivot = row;
                for (size_t i = row + 1; i < temp.rows_m; ++i) {
                    if (std::abs(temp(i, col)) > std::abs(temp(pivot, col))) {
                        pivot = i;
                    }
                }

                if (std::abs(temp(pivot, col)) < EPS) {
                    ++col;  // No pivot in this column
                    continue;
                }

                // Swap current row with pivot row
                for (size_t i = 0; i < temp.cols_m; ++i) {
                    std::swap(temp(row, i), temp(pivot, i));
                }

                // Eliminate below
                for (size_t i = row + 1; i < temp.rows_m; ++i) {
                    T factor = temp(i, col) / temp(row, col);
                    for (size_t j = col; j < temp.cols_m; ++j) {
                        temp(i, j) -= factor * temp(row, j);
                    }
                }

                ++rank;
                ++row;
                ++col;
            }

            return rank;
        }

        [[nodiscard]] vector<vector<T>> basis() const {
            matrix<T> temp(*this);
            const T EPS = static_cast<T>(1e-9);
            size_t m = temp.rows_m;
            size_t n = temp.cols_m;
            vector<size_t> pivot_columns;
            size_t row = 0;

            for (size_t col = 0; col < n && row < m; ++col) {
                size_t pivot = row;
                for (size_t i = row + 1; i < m; ++i) {
                    if (std::abs(temp(i, col)) > std::abs(temp(pivot, col))) {
                        pivot = i;
                    }
                }

                if (std::abs(temp(pivot, col)) < EPS) {
                    continue;
                }

                for (size_t j = 0; j < n; ++j) {
                    std::swap(temp(row, j), temp(pivot, j));
                }

                T pivot_val = temp(row, col);
                for (size_t j = col; j < n; ++j) {
                    temp(row, j) /= pivot_val;
                }

                for (size_t i = 0; i < m; ++i) {
                    if (i != row && std::abs(temp(i, col)) > EPS) {
                        T factor = temp(i, col);
                        for (size_t j = col; j < n; ++j) {
                            temp(i, j) -= factor * temp(row, j);
                        }
                    }
                }

                pivot_columns.push_back(col);
                ++row;
            }

            vector<vector<T>> basis_vectors;
            for (size_t col : pivot_columns) {
                vector<T> vec(m);
                for (size_t r = 0; r < m; ++r) {
                    vec[r] = (*this)(r, col);
                }
                basis_vectors.push_back(vec);
            }

            return basis_vectors;
        }

    }; // class matrix

    template <typename T>
    matrix<T> operator*(matrix<T> fst, const matrix<T>& snd) {
        fst *= snd;
        return fst;
    }

    template <typename T>
    matrix<T> operator*(matrix<T> fst, const T& snd) {
        fst *= snd;
        return fst;
    }

    template <typename T>
    matrix<T> operator*(const T& fst, matrix<T> snd) {
        snd *= fst;
        return snd;
    }

    template <typename T>
    matrix<T> operator+(const matrix<T>& lhs, const matrix<T>& rhs) {
        matrix<T> result(lhs);
        result += rhs;
        return result;
    }
} // namespace linalg

#include "squareMatrix.h"
namespace linalg{
    template <typename T>
    matrix<T> matrix<T>::pinv() const {
        auto AtA = static_cast<squareMatrix<T>>(this->transpose() * (*this));
        return AtA.inverse() * this->transpose();
    }
} // namespace linalg

#endif //LINALG_MATRIX_H


##### ./include/tensor.h #####

// This is a personal academic project. Dear PVS-Studio, please check it.
// PVS-Studio Static Code Analyzer for C, C++, C#, and Java: https://pvs-studio.com

#ifndef LINALG_NDMATRIX_H
#define LINALG_NDMATRIX_H

#include <iostream>
#include <array>
#include <stdexcept>
#include <initializer_list>
#include <cmath>

#include "vector.h"

namespace linalg {
    template <typename T, size_t N>
    class tensor {
    protected:
        vector<T> data_m;
        std::array<size_t, N> dims_m;

        size_t total_size() const {
            size_t total = 1;
            for (size_t i = 0; i < N; ++i) {
                total *= dims_m[i];
            }
            return total;
        }

        template <typename... Indices>
        size_t calculate_index(size_t iter, size_t idx, Indices... indices) const {
            size_t stride = 1;
            for (size_t i = iter + 1; i < N; ++i) {
                stride *= dims_m[i];
            }
            return idx * stride + calculate_index(iter + 1, indices...);

        }
        size_t calculate_index(size_t iter) const {
            if (iter != N) {
                throw std::invalid_argument("Number of arguments does not match dimentionality of the tensor");
            }
            return 0;
        }

    public:
        template <typename... Indices>
        explicit tensor(Indices ... indices) : data_m() {
            static_assert(sizeof...(Indices) == N, "Number of indices must match the dimension N");
            static_assert((std::is_convertible_v<Indices, size_t> && ...), "All indices must be convertible to size_t");

            dims_m = { static_cast<size_t>(indices)... };
            data_m.resize(total_size());
        }

        template <typename... Indices>
        explicit tensor(const vector<T>& data, Indices... indices)
                : tensor(indices...){
            data_m = data;
            data_m.resize(total_size());

        }

        tensor<T, N>& reshape(std::initializer_list<size_t> new_dims) {
            if (new_dims.size() != N) {
                throw std::invalid_argument("Dimension size does not match template parameter N.");
            }

            size_t new_total_size = 1;
            for (auto dim : new_dims) {
                new_total_size *= dim;
            }

            if (new_total_size != total_size()) {
                throw std::invalid_argument("New shape must have the same total size as the current shape.");
            }

            std::copy(new_dims.begin(), new_dims.end(), dims_m.begin());

            return *this;
        }

        size_t get_total_size() const {
            return total_size();
        }

        const vector<T>& get_data() const {
            return data_m;
        }

        bool operator==(const tensor<T, N>& other) const {
            for (size_t i = 0; i < data_m.size(); ++i) {
                if (data_m[i] != other.data_m[i]) {
                    return false;
                }
            }
            return true;
        }

        vector<T>& get_data() {
            return data_m;
        }

        tensor operator+= (const tensor<T, N>& other) {
            if (this->dims_m != other.dims_m) {
                throw std::invalid_argument("Matrices must have the same dimensions");
            }

            for (size_t i = 0; i < total_size(); ++i) {
                this->data_m[i] += other.data_m[i];
            }

            return *this;
        }

        tensor operator-= (const tensor<T, N>& other) {
            if (this->dims_m != other.dims_m) {
                throw std::invalid_argument("Matrices must have the same dimensions");
            }

            for (size_t i = 0; i < total_size(); ++i) {
                this->data_m[i] -= other.data_m[i];
            }

            return *this;
        }

        tensor<T, N> multiply(const tensor<T, N>& other) const {
            auto lhs_shape = this->dims_m;
            auto rhs_shape = other.dims_m;

            if (lhs_shape[1] != rhs_shape[0]) {
                throw std::invalid_argument("Incompatible dimensions for matrix multiplication.");
            }

            size_t m = lhs_shape[0];
            size_t n = rhs_shape[1];
            size_t p = lhs_shape[1];
            vector<T> result_data(m * n, 0);

            for (size_t i = 0; i < m; ++i) {
                for (size_t j = 0; j < n; ++j) {
                    for (size_t k = 0; k < p; ++k) {
                        result_data[i * n + j] += this->data_m[i * p + k] * other.data_m[k * n + j];
                    }
                }
            }

            return tensor<T, N>(result_data, m, n);
        }

        template <typename... Indices>
        T& operator()(Indices... indices) {
            static_assert(sizeof...(Indices) == N, "operator() requires exactly N indices.");
            return data_m[calculate_index(0, indices...)];
        }

        template <typename... Indices>
        const T& operator()(Indices... indices) const {
            return data_m[calculate_index(0, indices...)];
        }

        std::array<size_t, N> shape() const { return dims_m; }
    };

    template <typename T, size_t N>
    tensor<T, N> operator+ (const tensor<T, N> &fst, const tensor<T, N>& snd) {
        tensor<T, N> result(fst);
        return result += snd;
    }

    template <typename T, size_t N>
    tensor<T, N> operator- (const tensor<T, N> &fst, const tensor<T, N>& snd) {
        tensor<T, N> result(fst);
        return result -= snd;
    }
} // namespace linalg
#endif //LINALG_NDMATRIX_H


##### ./include/squareMatrix.h #####

// This is a personal academic project. Dear PVS-Studio, please check it.
// PVS-Studio Static Code Analyzer for C, C++, C#, and Java: http://www.viva64.com


#ifndef SQUAREMATRIX_H
#define SQUAREMATRIX_H

#include "matrix.h"

namespace linalg {
    template <typename T>
    class squareMatrix : public matrix<T> {
        size_t a;
    protected:
        squareMatrix<T> submatrix(size_t row, size_t col) {
            vector<T> sub_data{};
            sub_data.reserve((this->rows_m - 1) * (this->cols_m - 1));
            for (size_t r = 0; r < this->rows_m; r++) {
                if (r == row) continue;
                for (size_t c = 0; c < this->cols_m; c++) {
                    if (c == col) continue;

                    sub_data.push_back(this->data_m[r * this->cols_m + c]);
                }
            }

            return squareMatrix<T>{a-1, sub_data};
        }

        vector<T> get_column(size_t colIndex) const {
            vector<T> col(this->a);
            for (size_t i = 0; i < this->a; i++) {
                col[i] = (*this)(i, colIndex);
            }
            return col;
        }

        void set_column(size_t colIndex, const vector<T>& colData)
        {
            for (size_t i = 0; i < this->a; i++) {
                (*this)(i, colIndex) = colData[i];
            }
        }

        T offDiagonalNorm() const {
            T sum = 0;
            for (size_t i = 0; i < a; i++) {
                for (size_t j = 0; j < a; j++) {
                    if (i != j) {
                        T val = (*this)(i,j);
                        sum += val * val;
                    }
                }
            }
            return std::sqrt(sum);
        }


    public:
        explicit squareMatrix(const size_t a, vector<T> data = {}):
            matrix<T>(a, a, data), a(a) {}

        explicit squareMatrix(const matrix<T> &other)
        : matrix<T>(other),  // or matrix<T>(other.data_m, other.rows_m, other.cols_m)
          a(other.rows_m)
        {
            if (other.rows_m != other.cols_m) {
                throw std::runtime_error("Not a square matrix!");
            }
        }

        explicit squareMatrix(matrix<T>&& other)
        : matrix<T>(std::move(other)), a(other.rows())
        {
            if (other.rows() != other.cols()) {
                throw std::runtime_error("Not a square matrix!");
            }
        }

        squareMatrix& operator=(const matrix<T>& other) {
            if (other.rows() != other.cols()) {
                throw std::runtime_error("Not a square matrix!");
            }

            if (this != &other) {
                matrix<T>::operator=(other);
                a = other.rows();
            }
            return *this;
        }

        squareMatrix& operator=(matrix<T>&& other) noexcept {
            if (other.rows() != other.cols()) {
                throw std::runtime_error("Not a square matrix!");
            }

            if (this != &other) {
                matrix<T>::operator=(std::move(other));
                a = other.rows();
            }

            return *this;
        }

        static squareMatrix<T> identity(size_t n) {
            vector<T> identity_data(n * n, T{0});
            for (size_t i = 0; i < n; ++i) {
                identity_data[i * n + i] = T{1};
            }
            return squareMatrix<T>(n, identity_data);
        }

        bool isSingular() {
            return determinant() == 0;
        }

        bool isSymmetrical() {
            for (size_t r = 0; r < a; r++) {
                for (size_t c = 0; c < a; c++) {
                    if ((*this)(r, c) != (*this)(c, r))
                        return false;
                }
            }
            return true;
        }

        bool isSkewSymmetrical() {
            for (size_t r = 0; r < a; r++) {
                for (size_t c = 0; c < a; c++) {
                    if (r == c)
                        continue;

                    if ((*this)(r, c) != -(*this)(c, r))
                        return false;
                }
            }
            return true;
        }

        T minor(size_t row, size_t col) {
            squareMatrix<T> sub = submatrix(row, col);
            return sub.determinant();
        }

        T cofactor(size_t row, size_t col) {
            return (((row + col) % 2 == 0) ? 1 : -1) * minor(row, col);
        }

        T determinant() {
            if (this->rows_m == 1)
                return this->data_m[0];

            if (this->rows_m == 2)
                return this->data_m[0] * this->data_m[3] - this->data_m[1] * this->data_m[2];

            T res = 0;
            for (size_t col = 0; col < this->cols_m; ++col) {
                T cof = cofactor(0, col);
                T val = (*this)(0, col);
                res += val * cof;
            }

            return res;
        }

        std::pair<squareMatrix<T>, squareMatrix<T>> qrDecompose() const {
            squareMatrix<T> Q(a);
            squareMatrix<T> R(a);

            for (size_t i = 0; i < a; i++) {
                for (size_t j = 0; j < a; j++) {
                    Q(i, j) = 0;
                    R(i, j) = 0;
                }
            }

            for (size_t k = 0; k < a; k++) {
                vector<T> vk = this->get_column(k);

                for (size_t j = 0; j < k; j++) {
                    vector<T> qj = Q.get_column(j);
                    T rjk = 0;
                    for (size_t i = 0; i < a; i++) {
                        rjk += qj[i] * vk[i];
                    }
                    R(j, k) = rjk;
                    for (size_t i = 0; i < a; i++) {
                        vk[i] -= rjk * qj[i];
                    }
                }

                T norm = vectorNorm(vk);
                if (norm < 1e-15) {
                    R(k, k) = 0;
                    for (size_t i = 0; i < a; i++) {
                        Q(i, k) = 0;
                    }
                } else {
                    R(k, k) = norm;
                    for (size_t i = 0; i < a; i++) {
                        Q(i, k) = vk[i] / norm;
                    }
                }
            }

            return {Q, R};
        }

        vector<T> eigenvalues(double tol = 1e-9, int maxIter = 1000) const {
            squareMatrix<T> A(*this);

            int iter = 0;
            while (iter < maxIter) {
                auto [Q, R] = A.qrDecompose();

                tensor<T, 2> multiplied = R.multiply(Q);
                A = squareMatrix<T>(A.a, multiplied.get_data());

                if (A.offDiagonalNorm() < tol) {
                    break;
                }
                iter++;
            }

            vector<T> eigvals(A.a);
            for (size_t i = 0; i < A.a; i++) {
                eigvals[i] = A(i, i);
            }
            return eigvals;
        }

        vector<T> nullSpace(double tol) const {
            squareMatrix<T> A = *this;
            size_t n = this->a;

            for (size_t i = 0; i < n; ++i) {
                size_t pivotRow = i;
                for (size_t j = i + 1; j < n; ++j) {
                    if (std::abs(A(j, i)) > std::abs(A(pivotRow, i))) {
                        pivotRow = j;
                    }
                }

                if (std::abs(A(pivotRow, i)) < tol) continue;

                if (pivotRow != i) {
                    for (size_t k = 0; k < n; ++k) std::swap(A(i, k), A(pivotRow, k));
                }

                for (size_t j = i + 1; j < n; ++j) {
                    T factor = A(j, i) / A(i, i);
                    for (size_t k = i; k < n; ++k) {
                        A(j, k) -= factor * A(i, k);
                    }
                }
            }

            vector<T> x(n, 0);
            x[n - 1] = 1;

            for (int i = static_cast<int>(n) - 2; i >= 0; --i) {
                T sum = 0;
                for (size_t j = i + 1; j < n; ++j) {
                    sum += A(i, j) * x[j];
                }
                if (std::abs(A(i, i)) < tol) {
                    x[i] = 1;
                } else {
                    x[i] = -sum / A(i, i);
                }
            }

            return x;
        }

        squareMatrix<T> eigenvectorsViaNullspace(double tol = 1e-9) const {
            vector<T> eigenvals = this->eigenvalues();
            vector<vector<T>> vecs;

            for (const T& lambda : eigenvals) {
                squareMatrix<T> shifted = *this;
                for (size_t i = 0; i < this->a; ++i) {
                    shifted(i, i) -= lambda;
                }

                vector<T> v = shifted.nullSpace(tol);

                if (vectorNorm(v) > tol) {
                    for (auto& x : v) x /= vectorNorm(v);
                    vecs.push_back(v);
                } else {
                    vecs.push_back(vector<T>(this->a, 0));
                }
            }

            squareMatrix<T> result(this->a);
            for (size_t col = 0; col < vecs.size(); ++col) {
                for (size_t row = 0; row < this->a; ++row) {
                    result(row, col) = vecs[col][row];
                }
            }

            return result;
        }


        squareMatrix<T> inverse() {
            T det = this->determinant();
            if (std::abs(det) < 1e-12) {
                throw std::runtime_error("Matrix is singular or nearly singular — cannot invert.");
            }

            vector<T> cofactors_data(this->rows_m * this->cols_m);

            for (size_t r = 0; r < this->rows_m; r++) {
                for (size_t c = 0; c < this->cols_m; c++) {
                    cofactors_data[r * this->cols_m + c] = this->cofactor(r, c);
                }
            }

            squareMatrix<T> cofactorMat(this->rows_m, cofactors_data);

            squareMatrix<T> adjugate(this->rows_m);
            for (size_t i = 0; i < this->rows_m; ++i) {
                for (size_t j = 0; j < this->cols_m; ++j) {
                    adjugate(i, j) = cofactorMat(j, i);
                }
            }

            for (auto& val : adjugate.data_m) {
                val /= det;
            }

            return adjugate;
        }

        std::pair<squareMatrix<T>, squareMatrix<T>> luDecompose() const {
            if (this->a != this->rows_m || this->a != this->cols_m) {
                throw std::runtime_error("LU decomposition only valid for square matrices");
            }

            squareMatrix<T> L(this->a);
            squareMatrix<T> U(this->a);

            for (size_t i = 0; i < this->a; i++) {
                // Fill U
                for (size_t j = i; j < this->a; j++) {
                    T sum = 0;
                    for (size_t k = 0; k < i; k++) {
                        sum += L(i, k) * U(k, j);
                    }
                    U(i, j) = (*this)(i, j) - sum;
                }

                // Fill L
                for (size_t j = i; j < this->a; j++) {
                    if (i == j) {
                        L(i, i) = 1;
                    } else {
                        T sum = 0;
                        for (size_t k = 0; k < i; k++) {
                            sum += L(j, k) * U(k, i);
                        }
                        L(j, i) = ((*this)(j, i) - sum) / U(i, i);
                    }
                }
            }

            return std::make_pair(L, U);
        }

        vector<T> solve(const vector<T>& b) const {
            if (b.size() != this->a) {
                throw std::runtime_error("Size of b must match matrix dimensions.");
            }

            auto [L, U] = this->luDecompose();

            vector<T> y(this->a);
            for (size_t i = 0; i < this->a; ++i) {
                T sum = 0;
                for (size_t j = 0; j < i; ++j) {
                    sum += L(i, j) * y[j];
                }
                y[i] = b[i] - sum;
            }

            vector<T> x(this->a);
            for (int i = static_cast<int>(this->a) - 1; i >= 0; --i) {
                T sum = 0;
                for (size_t j = i + 1; j < this->a; ++j) {
                    sum += U(i, j) * x[j];
                }
                x[i] = (y[i] - sum) / U(i, i);
            }

            return x;
        }

        vector<vector<T>> eigenvectorsViaSolving(vector<T> eigenvalues, double tol = 1e-9) const {
            vector<vector<T>> eigenvectors;

            for (T lambda : eigenvalues) {
                // Form A - lambda * I
                squareMatrix<T> shifted = *this;
                for (size_t i = 0; i < this->a; ++i) {
                    shifted(i, i) -= lambda;
                }

                // We'll try to find x such that (A - λI)x = 0
                // Let’s feed a random b and normalize the result
                vector<T> b(this->a, 1.0); // or random vector, if you prefer
                vector<T> x;

                try {
                    x = shifted.solve(b);  // Will fail if matrix is singular
                } catch (...) {
                    // Matrix likely singular => try alternate approach
                    x = vector<T>(this->a, 0);
                }

                // Normalize eigenvector
                T norm = vectorNorm(x);
                if (norm > tol) {
                    for (T& val : x) val /= norm;
                    eigenvectors.push_back(x);
                }
            }

            return eigenvectors;
        }
    };

    template <typename T>
    squareMatrix<T> operator+(matrix<T> lhs, const matrix<T>& rhs) {
        lhs += rhs;
        return lhs;
    }
} // namespace linalg

#endif //SQUAREMATRIX_H


##### ./include/vector.h #####

// This is a personal academic project. Dear PVS-Studio, please check it.
// PVS-Studio Static Code Analyzer for C, C++, C#, and Java: https://pvs-studio.com

#ifndef LINALG_VECTOR_H
#define LINALG_VECTOR_H

#include <cmath>
#include <algorithm>
#include <stdexcept>
#include <iterator>
#include <initializer_list>
#include <compare>

namespace linalg {
    template<typename T>
    class vector {
    private:
        T* data_;
        size_t size_;
        size_t capacity_;

    public:
        using value_type = T;

        vector() noexcept
            : data_(nullptr), size_(0), capacity_(0) {}

        vector(size_t count, const T& value)
            : data_(nullptr), size_(0), capacity_(0) {
            reserve(count);
            for (size_t i = 0; i < count; ++i)
                new (&data_[i]) T(value);
            size_ = count;
        }

        explicit vector(size_t len)
        : data_(nullptr), size_(0), capacity_(0) {
            reserve(len);
            for (size_t i = 0; i < len; ++i)
                new (&data_[i]) T();
            size_ = len;
        }

        template<typename InputIt>
        vector(InputIt first, InputIt last)
            : data_(nullptr), size_(0), capacity_(0) {
            size_t count = std::distance(first, last);
            reserve(count);
            std::copy(first, last, data_);
            size_ = count;
        }

        vector(std::initializer_list<T> init)
        : data_(static_cast<T*>(::operator new(init.size() * sizeof(T)))),
          size_(init.size()),
          capacity_(init.size())
        {
            size_t i = 0;
            try {
                for (const auto& item : init) {
                    new (&data_[i++]) T(item);
                }
            } catch (...) {
                for (size_t j = 0; j < i; ++j) {
                    data_[j].~T();
                }
                ::operator delete(data_);
                throw;
            }
        }

        vector(const vector& other)
        : data_(static_cast<T*>(::operator new(other.capacity_ * sizeof(T)))),
          size_(other.size_),
          capacity_(other.capacity_)
        {
            for (size_t i = 0; i < size_; ++i) {
                new (&data_[i]) T(other.data_[i]);  // deep copy each element
            }
        }

        vector(vector&& other) noexcept
            : data_(other.data_),
              size_(other.size_),
              capacity_(other.capacity_)
        {
            other.data_ = nullptr;
            other.size_ = 0;
            other.capacity_ = 0;
        }

        ~vector() {
            clear();  // Explicitly destroys all elements
            ::operator delete(data_);  // Raw memory deallocation without calling destructors
        }

        vector& operator=(const vector& other) {
            if (this != &other) {
                vector temp(other);
                swap(temp);
            }
            return *this;
        }

        vector& operator=(vector&& other) noexcept {
            if (this != &other) {
                clear();
                ::operator delete(data_);
                data_ = other.data_;
                size_ = other.size_;
                capacity_ = other.capacity_;
                other.data_ = nullptr;
                other.size_ = other.capacity_ = 0;
            }
            return *this;
        }

        T& operator[](size_t index) noexcept { return data_[index]; }
        const T& operator[](size_t index) const noexcept { return data_[index]; }

        T& at(size_t index) {
            if (index >= size_) throw std::out_of_range("vector::at");
            return data_[index];
        }
        const T& at(size_t index) const {
            if (index >= size_) throw std::out_of_range("vector::at");
            return data_[index];
        }

        T& front() {
            if (is_empty()) throw std::out_of_range("vector::front");
            return data_[0];
        }
        const T& front() const {
            if (is_empty()) throw std::out_of_range("vector::front");
            return data_[0];
        }

        T& back() {
            if (is_empty()) throw std::out_of_range("vector::back");
            return data_[size_ - 1];
        }
        const T& back() const {
            if (is_empty()) throw std::out_of_range("vector::back");
            return data_[size_ - 1];
        }

        T* begin() noexcept { return data_; }
        T* end() noexcept { return data_ + size_; }
        const T* begin() const noexcept { return data_; }
        const T* end() const noexcept { return data_ + size_; }
        const T* cbegin() const noexcept { return data_; }
        const T* cend() const noexcept { return data_ + size_; }

        auto rbegin() noexcept { return std::reverse_iterator<T*>(end()); }
        auto rend() noexcept { return std::reverse_iterator<T*>(begin()); }
        auto rbegin() const noexcept { return std::reverse_iterator<const T*>(end()); }
        auto rend() const noexcept { return std::reverse_iterator<const T*>(begin()); }
        auto rcbegin() const noexcept { return rbegin(); }
        auto rcend() const noexcept { return rend(); }

        bool is_empty() const noexcept { return size_ == 0; }
        size_t size() const noexcept { return size_; }
        size_t capacity() const noexcept { return capacity_; }

        void reserve(size_t new_cap) {
            if (new_cap <= capacity_) return;

            T* new_data = static_cast<T*>(::operator new(new_cap * sizeof(T)));

            for (size_t i = 0; i < size_; ++i) {
                new (&new_data[i]) T(std::move_if_noexcept(data_[i]));
                data_[i].~T();
            }

            ::operator delete(data_);
            data_ = new_data;
            capacity_ = new_cap;
        }

        void shrink_to_fit() {
            if (size_ < capacity_) {
                T* new_data = nullptr;
                if (size_) {
                    new_data = static_cast<T*>(::operator new(size_ * sizeof(T)));
                    for (size_t i = 0; i < size_; ++i) {
                        new (&new_data[i]) T(std::move_if_noexcept(data_[i]));
                        data_[i].~T();
                    }
                }
                ::operator delete(data_);
                data_ = new_data;
                capacity_ = size_;
            }
        }

        void clear() noexcept {
            for (size_t i = 0; i < size_; ++i)
                data_[i].~T();
            size_ = 0;
        }

        void resize(size_t count, const T& value = T()) {
            if (count < size_) {
                for (size_t i = count; i < size_; ++i)
                    data_[i].~T();
            } else if (count > size_) {
                reserve(count);
                for (size_t i = size_; i < count; ++i)
                    new (&data_[i]) T(value);
            }
            size_ = count;
        }

        void swap(vector& other) noexcept {
            std::swap(data_, other.data_);
            std::swap(size_, other.size_);
            std::swap(capacity_, other.capacity_);
        }

        T* insert(T* pos, const T& value) {
            size_t idx = pos - data_;
            if (pos < data_ || pos > end()) throw std::out_of_range("insert");
            if (size_ == capacity_) reserve(capacity_ ? capacity_ * 2 : 1);
            pos = data_ + idx;
            for (size_t i = size_; i > idx; --i) {
                new (&data_[i]) T(std::move_if_noexcept(data_[i - 1]));
                data_[i - 1].~T();
            }
            new (&data_[idx]) T(value);
            ++size_;
            return data_ + idx;
        }

        template<typename InputIt>
        T* insert(T* pos, InputIt first, InputIt last) {
            size_t idx = pos - data_;
            size_t count = std::distance(first, last);
            if (pos < data_ || pos > end()) throw std::out_of_range("insert range");
            if (size_ + count > capacity_) reserve(std::max(capacity_ * 2, size_ + count));
            pos = data_ + idx;
            for (size_t i = size_; i > idx; --i) {
                new (&data_[i + count - 1]) T(std::move_if_noexcept(data_[i - 1]));
                data_[i - 1].~T();
            }
            for (size_t i = 0; i < count; ++i)
                new (&data_[idx + i]) T(*std::next(first, i));
            size_ += count;
            return data_ + idx;
        }

        T* erase(T* pos) {
            if (pos < data_ || pos >= end()) throw std::out_of_range("erase");
            size_t idx = pos - data_;
            data_[idx].~T();
            for (size_t i = idx; i < size_ - 1; ++i) {
                new (&data_[i]) T(std::move_if_noexcept(data_[i + 1]));
                data_[i + 1].~T();
            }
            --size_;
            return data_ + idx;
        }

        T* erase(T* first, T* last) {
            if (first < data_ || last > end() || first > last) throw std::out_of_range("erase range");
            size_t idx = first - data_;
            size_t count = last - first;
            for (size_t i = 0; i < count; ++i)
                data_[idx + i].~T();
            for (size_t i = idx + count; i < size_; ++i) {
                new (&data_[i - count]) T(std::move_if_noexcept(data_[i]));
                data_[i].~T();
            }
            size_ -= count;
            return data_ + idx;
        }

        void push_back(const T& value) {
            if (size_ == capacity_) {
                // handle self reference
                T value_copy = value;
                reserve(capacity_ ? capacity_ * 2 : 1);
                new (&data_[size_++]) T(std::move(value_copy));
            } else {
                new (&data_[size_++]) T(value);
            }
        }

        void concat(const vector<T>& v2) {
            reserve(this->size() + v2.size());
            std::copy(v2.begin(), v2.end(), std::back_inserter(*this));
        }

        void pop_back() {
            if (is_empty()) throw std::out_of_range("pop_back");
            data_[--size_ - 1].~T();
        }

        template<typename... Args>
        void emplace_back(Args&&... args) {
            if (size_ == capacity_)
                reserve(capacity_ ? capacity_ * 2 : 1);
            new (&data_[size_++]) T(std::forward<Args>(args)...);
        }

        auto operator<=>(const vector& other) const {
            return std::lexicographical_compare_three_way(
                begin(), end(), other.begin(), other.end());
        }

        bool operator==(const vector& other) const {
            if (size_ != other.size_) return false;
            for (size_t i = 0; i < size_; ++i)
                if (!(data_[i] == other.data_[i]))
                    return false;
            return true;
        }
    };

    template<typename T>
    T vectorNorm(const vector<T>& v) {
        T sum = 0;
        for (auto &val : v) sum += val * val;
        return std::sqrt(sum);
    }
} // namespace linalg

#endif //LINALG_VECTOR_H


##### ./include/linalg.h #####

// This is a personal academic project. Dear PVS-Studio, please check it.
// PVS-Studio Static Code Analyzer for C, C++, C#, and Java: https://pvs-studio.com

#ifndef LINALG_H
#define LINALG_H

#include "vector.h"
#include "tensor.h"
#include "matrix.h"
#include "squareMatrix.h"

#endif // LINALG_H


##### ./benchmarks/benchmark.cpp #####

#include <iostream>
#include <chrono>
#include <fstream>
#include <vector>
#include <Eigen/Dense>
#include "matrix.h"

using namespace std::chrono;

// Generic benchmarking function (in milliseconds)
template <typename Func>
double benchmark(Func func, int repetitions = 10) {
    double total_time = 0.0;
    for (int i = 0; i < repetitions; ++i) {
        auto start = high_resolution_clock::now();
        func();
        auto end = high_resolution_clock::now();
        total_time += duration<double, std::milli>(end - start).count();
    }
    return total_time / repetitions;
}

void run_addition_benchmark(std::ofstream& file, int size, int repetitions) {
    linalg::matrix<float> my_a(size, size), my_b(size, size);
    for (size_t i = 0; i < my_a.get_total_size(); ++i) {
        my_a.get_data()[i] = 1.0f;
        my_b.get_data()[i] = 2.0f;
    }

    Eigen::MatrixXf eigen_a = Eigen::MatrixXf::Constant(size, size, 1.0f);
    Eigen::MatrixXf eigen_b = Eigen::MatrixXf::Constant(size, size, 2.0f);

    double mylib_time = benchmark([&]() {
        linalg::matrix<float> c(my_a);
        c += my_b;
    }, repetitions);

    double eigen_time = benchmark([&]() {
        Eigen::MatrixXf c = eigen_a + eigen_b;
    }, repetitions);

    file << size << "," << mylib_time << "," << eigen_time << "\n";
}

void run_multiplication_benchmark(std::ofstream& file, int size, int repetitions) {
    linalg::matrix<float> my_a(size, size), my_b(size, size);
    for (size_t i = 0; i < my_a.get_total_size(); ++i) {
        my_a.get_data()[i] = 1.0f;
        my_b.get_data()[i] = 1.0f;
    }

    Eigen::MatrixXf eigen_a = Eigen::MatrixXf::Constant(size, size, 1.0f);
    Eigen::MatrixXf eigen_b = Eigen::MatrixXf::Constant(size, size, 1.0f);

    double mylib_time = benchmark([&]() {
        linalg::matrix<float> c = my_a * my_b;
    }, repetitions);

    double eigen_time = benchmark([&]() {
        Eigen::MatrixXf c = eigen_a * eigen_b;
    }, repetitions);

    file << size << "," << mylib_time << "," << eigen_time << "\n";
}

int main() {
    std::ofstream add_file("addition_results.csv");
    std::ofstream mult_file("multiplication_results.csv");

    add_file << "Size,YourMatrix(ms),Eigen(ms)\n";
    mult_file << "Size,YourMatrix(ms),Eigen(ms)\n";

    int repetitions = 10;

    for (int size = 100; size <= 1000; size += 100) {
        std::cout << "Running benchmarks for size: " << size << "...\n";
        run_addition_benchmark(add_file, size, repetitions);
        run_multiplication_benchmark(mult_file, size, repetitions);
    }

    add_file.close();
    mult_file.close();

    std::cout << "Benchmarks completed. Results saved to CSV files.\n";
    return 0;
}


##### ./benchmarks/eigenvalue_benchmark.cpp #####

#include <iostream>
#include <chrono>
#include <fstream>
#include "linalg.h"
#include <cmath>
#include <random>
#include <Eigen/Dense>
#include "squareMatrix.h"

using namespace std;
using namespace std::chrono;

template<typename Func>
double benchmark(Func func, int repetitions = 10) {
    double total_time = 0.0;
    for (int i = 0; i < repetitions; ++i) {
        auto start = high_resolution_clock::now();
        func();
        auto end = high_resolution_clock::now();
        total_time += duration<double, std::milli>(end - start).count(); // milliseconds
    }
    return total_time / repetitions;
}

// Generate symmetric matrix of size n x n
linalg::squareMatrix<double> generate_symmetric_matrix(size_t n) {
    linalg::vector<double> data(n * n, 0);
    std::mt19937 gen(random_device{}());
    std::uniform_real_distribution<> dis(-10.0, 10.0);

    for (size_t i = 0; i < n; ++i) {
        for (size_t j = i; j < n; ++j) {
            double val = dis(gen);
            data[i * n + j] = val;
            data[j * n + i] = val;
        }
    }

    return linalg::squareMatrix<double>(n, data);
}

void run_benchmark(const std::string& output_csv, int min_size = 5, int max_size = 75, int step = 5, int repetitions = 10) {
    ofstream file(output_csv);
    file << "Size,YourMatrix(ms),Eigen(ms)\n";

    for (int size = min_size; size <= max_size; size += step) {
        cout << "Benchmarking size: " << size << "..." << endl;

        double total_your_time = 0;
        double total_eigen_time = 0;

        for (int rep = 0; rep < repetitions; ++rep) {
            linalg::squareMatrix<double> my_mat = generate_symmetric_matrix(size);

            // Copy to Eigen
            Eigen::MatrixXd eigen_mat(size, size);
            for (int r = 0; r < size; ++r)
                for (int c = 0; c < size; ++c)
                    eigen_mat(r, c) = my_mat(r, c);

            // Your lib
            total_your_time += benchmark([&]() {
                volatile auto eigvals = my_mat.eigenvalues();
            }, 1); // 1 rep here since outer loop controls it

            // Eigen
            total_eigen_time += benchmark([&]() {
                Eigen::EigenSolver<Eigen::MatrixXd> solver(eigen_mat);
                volatile auto eigvals = solver.eigenvalues();
            }, 1);
        }

        double avg_your_time = total_your_time / repetitions;
        double avg_eigen_time = total_eigen_time / repetitions;

        file << size << "," << avg_your_time << "," << avg_eigen_time << "\n";
    }

    file.close();
    cout << "Benchmark complete! Results saved to: " << output_csv << endl;
}

int main() {
    run_benchmark("eigenvalue_benchmark.csv");
    return 0;
}


##### ./tests/test_vector.cpp #####

#include <gtest/gtest.h>
#include "linalg.h"
#include <stdexcept>
#include <initializer_list>
#include <iterator>
#include <algorithm>
#include <string>

TEST(vector, DefaultConstructor) {
    linalg::vector<int> v;
    EXPECT_TRUE(v.is_empty());
    EXPECT_EQ(v.size(), 0);
}

TEST(vector, FillConstructor) {
    linalg::vector<int> v(static_cast<size_t>(5), 42);
    EXPECT_EQ(v.size(), 5);
    for (int i = 0; i < 5; ++i)
        EXPECT_EQ(v[i], 42);
}

TEST(vector, IteratorConstructor) {
    std::vector<int> source = {1, 2, 3, 4};
    linalg::vector<int> v(source.begin(), source.end());
    EXPECT_EQ(v.size(), 4);
    EXPECT_EQ(v[2], 3);
}

TEST(vector, InitializerListConstructor) {
    linalg::vector<std::string> v{"a", "b", "c"};
    EXPECT_EQ(v.size(), 3);
    EXPECT_EQ(v[0], "a");
    EXPECT_EQ(v[1], "b");
    EXPECT_EQ(v[2], "c");
}

TEST(vector, CopyConstructor) {
    linalg::vector<int> v1{1, 2, 3};
    linalg::vector<int> v2 = v1;
    EXPECT_EQ(v2, v1);
}

TEST(vector, MoveConstructor) {
    linalg::vector<int> temp{5, 6};
    linalg::vector<int> v = std::move(temp);
    EXPECT_EQ(v.size(), 2);
    EXPECT_EQ(v[0], 5);
    EXPECT_EQ(v[1], 6);
}

TEST(vector, CopyAssignment) {
    linalg::vector<int> a{1, 2, 3};
    linalg::vector<int> b;
    b = a;
    EXPECT_EQ(a, b);
}

TEST(vector, MoveAssignment) {
    linalg::vector<int> a{1, 2};
    linalg::vector<int> b;
    b = std::move(a);
    EXPECT_EQ(b.size(), 2);
    EXPECT_EQ(b[0], 1);
    EXPECT_EQ(b[1], 2);
}

TEST(vector, IndexOperator) {
    linalg::vector<char> v{'a', 'b'};
    EXPECT_EQ(v[1], 'b');
}

TEST(vector, AtThrowsOutOfBounds) {
    linalg::vector<int> v{1, 2, 3};
    EXPECT_THROW(v.at(10), std::out_of_range);
}

TEST(vector, FrontBack) {
    linalg::vector<int> v{10, 20, 30};
    EXPECT_EQ(v.front(), 10);
    EXPECT_EQ(v.back(), 30);
}

TEST(vector, Iterators) {
    linalg::vector<int> v{1, 2, 3};
    auto it = std::find(v.begin(), v.end(), 2);
    EXPECT_NE(it, v.end());
    EXPECT_EQ(*it, 2);
}

TEST(vector, BackInserterCompatibility) {
    linalg::vector<int> v;
    std::vector<int> source = {1, 2, 3};
    std::copy(source.begin(), source.end(), std::back_inserter(v));
    EXPECT_EQ(v.size(), 3);
    EXPECT_EQ(v.back(), 3);
}

TEST(vector, CapacityManagement) {
    linalg::vector<int> v;
    v.reserve(10);
    EXPECT_GE(v.capacity(), 10);
    v.shrink_to_fit();
    EXPECT_LE(v.capacity(), 10);
}

TEST(vector, ResizeAndClear) {
    linalg::vector<int> v{1, 2, 3};
    v.resize(5);
    EXPECT_EQ(v.size(), 5);
    v.clear();
    EXPECT_TRUE(v.is_empty());
}

TEST(vector, ResizeShrink) {
    linalg::vector<int> v{1, 2, 3, 4, 5};
    v.resize(3);
    EXPECT_EQ(v.size(), 3);
    EXPECT_EQ(v[0], 1);
    EXPECT_EQ(v[2], 3);
}

TEST(vector, ResizeGrowDefault) {
    linalg::vector<int> v{1, 2};
    v.resize(5);
    EXPECT_EQ(v.size(), 5);
    EXPECT_EQ(v[2], {});
}

TEST(vector, InsertSingle) {
    linalg::vector<int> v{1, 3};
    auto it = v.insert(v.begin() + 1, 2);
    EXPECT_EQ(*it, 2);
    EXPECT_EQ(v[1], 2);
}

TEST(vector, InsertAtBeginEmpty) {
    linalg::vector<int> v;
    v.insert(v.begin(), 42);
    EXPECT_EQ(v.size(), 1);
    EXPECT_EQ(v[0], 42);
}

TEST(vector, InsertAtEnd) {
    linalg::vector<int> v{1, 2, 3};
    v.insert(v.end(), 4);
    EXPECT_EQ(v.size(), 4);
    EXPECT_EQ(v[3], 4);
}

TEST(vector, InsertRange) {
    linalg::vector<int> v{1, 5};
    std::vector<int> to_insert{2, 3, 4};
    v.insert(v.begin() + 1, to_insert.begin(), to_insert.end());
    EXPECT_EQ(v[2], 3);
}

TEST(vector, EraseSingle) {
    linalg::vector<int> v{1, 2, 3};
    auto it = v.erase(v.begin() + 1);
    EXPECT_EQ(*it, 3);
    EXPECT_EQ(v.size(), 2);
}

TEST(vector, EraseRange) {
    linalg::vector<int> v{1, 2, 3, 4, 5};
    auto it = v.erase(v.begin() + 1, v.begin() + 4);
    EXPECT_EQ(*it, 5);
    EXPECT_EQ(v.size(), 2);
}

TEST(vector, EraseFromEmpty) {
    linalg::vector<int> v;
    EXPECT_THROW(v.erase(v.begin()), std::out_of_range);
}

TEST(vector, PushPopEmplaceBack) {
    linalg::vector<std::string> v;
    v.push_back("hi");
    v.emplace_back("there");
    EXPECT_EQ(v.size(), 2);
    EXPECT_EQ(v.back(), "there");
    v.pop_back();
    EXPECT_EQ(v.size(), 1);
}

TEST(vector, ComparisonOperators) {
    linalg::vector<int> a{1, 2, 3};
    linalg::vector<int> b{1, 2, 4};
    EXPECT_TRUE(a < b);
    EXPECT_TRUE(a != b);
    EXPECT_FALSE(a == b);
}

TEST(vector, SwapMethod) {
    linalg::vector<int> a{1, 2}, b{3, 4};
    a.swap(b);
    EXPECT_EQ(a[0], 3);
    EXPECT_EQ(b[0], 1);
}

TEST(vector, SwapWithEmptyVector) {
    linalg::vector<int> v1{1, 2, 3};
    linalg::vector<int> v2;
    v1.swap(v2);
    EXPECT_EQ(v1.size(), 0);
    EXPECT_EQ(v2.size(), 3);
    EXPECT_EQ(v2[0], 1);
}

TEST(vector, NestedVectorsBasic) {
    linalg::vector<linalg::vector<int>> vv;
    linalg::vector<int> inner1 = {1, 2, 3};
    linalg::vector<int> inner2 = {4, 5};

    vv.push_back(inner1);
    vv.push_back(inner2);

    ASSERT_EQ(vv.size(), 2);
    EXPECT_EQ(vv[0].size(), 3);
    EXPECT_EQ(vv[1][1], 5);
}

TEST(vector, NestedVectorsEmplaceBack) {
    linalg::vector<linalg::vector<int>> vv;
    vv.emplace_back(linalg::vector<int>{1, 2});
    vv.emplace_back(linalg::vector<int>{3, 4});

    EXPECT_EQ(vv.size(), 2);
    EXPECT_EQ(vv[0].front(), 1);
    EXPECT_EQ(vv[1].back(), 4);
}

TEST(vector, PushBackSelfBack) {
    linalg::vector<int> v;
    for (int i = 0; i < 10; ++i) {
        v.push_back(i);
    }

    int last = v.back();
    v.push_back(last);

    EXPECT_EQ(v.size(), 11);
    EXPECT_EQ(v.back(), 9);
}

TEST(vector, NestedPushBackSelfBack) {
    linalg::vector<linalg::vector<int>> v;
    linalg::vector<int> tmp = {1, 2};
    v.push_back(tmp);
    v.push_back(v.back()); // Copy of the last vector

    ASSERT_EQ(v.size(), 2);
    EXPECT_EQ(v[1], v[0]); // Must be deep copy
}



##### ./tests/test_squareMatrix.cpp #####

#include <gtest/gtest.h>
#include "linalg.h"

TEST(SquareMatrixTests, Inverse) {
    linalg::squareMatrix<double> A(2, {4, 7, 2, 6});
    auto Ainv = A.inverse();
    auto result = A.multiply(Ainv);
    auto expected = linalg::squareMatrix<double>::identity(2);

    const auto& res_data = result.get_data();
    const auto& exp_data = expected.get_data();

    for (size_t i = 0; i < res_data.size(); ++i) {
        EXPECT_NEAR(res_data[i], exp_data[i], 1e-6);
    }
}

TEST(SquareMatrixTests, LUDecomposition) {
    linalg::squareMatrix<double> A(2, {4, 3, 6, 3});
    auto [L, U] = A.luDecompose();
    auto recomposed = L.multiply(U);

    const auto& orig = A.get_data();
    const auto& recomposed_data = recomposed.get_data();
    for (size_t i = 0; i < orig.size(); ++i) {
        EXPECT_NEAR(orig[i], recomposed_data[i], 1e-6);
    }
}

TEST(SquareMatrixTests, SolveEquation) {
    linalg::squareMatrix<double> A(2, {2, 1, 5, 7});
    linalg::vector<double> b = {11, 13};
    linalg::vector<double> expected_x = {7.1111, -3.2222};

    auto x = A.solve(b);

    ASSERT_EQ(x.size(), expected_x.size());
    for (size_t i = 0; i < x.size(); ++i) {
        EXPECT_NEAR(x[i], expected_x[i], 0.01);
    }
}

##### ./tests/test_matrix.cpp #####

#include <gtest/gtest.h>
#include "linalg.h"
#include <cmath>


TEST(MatrixConstructorTest, ColumnVectorInitialization) {
    linalg::vector<linalg::vector<int>> data = {
        {1, 2, 3},
        {4, 5, 6},
        {7, 8, 9}
    };

    linalg::matrix<int> m(data);

    EXPECT_EQ(m.cols(), 3);
    EXPECT_EQ(m.rows(), 3);

    EXPECT_EQ(m(0, 0), 1);
    EXPECT_EQ(m(0, 1), 2);
    EXPECT_EQ(m(0, 2), 3);
    EXPECT_EQ(m(1, 0), 4);
    EXPECT_EQ(m(1, 1), 5);
    EXPECT_EQ(m(1, 2), 6);
    EXPECT_EQ(m(2, 0), 7);
    EXPECT_EQ(m(2, 1), 8);
    EXPECT_EQ(m(2, 2), 9);
}

TEST(MatrixConstructorTest, HandlesEmptyColumnVector) {
    linalg::vector<linalg::vector<int>> empty_data;
    linalg::matrix<int> m(empty_data);

    EXPECT_EQ(m.cols(), 0);
    EXPECT_EQ(m.rows(), 0);
}

TEST(MatrixConstructorTest, PadsShortRows) {
    linalg::vector<linalg::vector<int>> jagged = {
        {1, 2},
        {3},
        {4, 5, 6}
    };

    linalg::matrix<int> m(jagged);

    EXPECT_EQ(m.cols(), 3);
    EXPECT_EQ(m.rows(), 3);

    EXPECT_EQ(m(0, 0), 1);
    EXPECT_EQ(m(0, 1), 2);
    EXPECT_EQ(m(0, 2), {});

    EXPECT_EQ(m(1, 0), 3);
    EXPECT_EQ(m(1, 1), {});
    EXPECT_EQ(m(1, 2), {});

    EXPECT_EQ(m(2, 0), 4);
    EXPECT_EQ(m(2, 1), 5);
    EXPECT_EQ(m(2, 2), 6);
}


TEST(MatrixTests, EigenvaluesAndVectors) {
    linalg::vector<double> data = {
        5, 10, -5,
        2, -14, 2,
        -4, -8, 6
    };
    linalg::squareMatrix<double> M(3, data);
    auto evals = M.eigenvalues();

    for (const auto& val : evals) {
        EXPECT_TRUE(std::isfinite(val));
    }

    auto evecs = M.eigenvectorsViaNullspace();
    EXPECT_EQ(evecs.rows(), 3);
    EXPECT_EQ(evecs.cols(), evals.size());
}

TEST(MatrixTests, PseudoInverse) {
    linalg::matrix<double> A(3, 2, {1, 2, 3, 4, 5, 6});
    auto A_p = A.pinv();

    // A * A.pinv() * A == A
    auto AA_pA = A * A_p * A;
    for (size_t r = 0; r < A.rows(); ++r) {
        for (size_t c = 0; c < A.cols(); ++c) {
            EXPECT_NEAR(A(r, c), AA_pA(r, c), 0.001);
        }
    }

    // A.pinv() * A * A.pinv() == A.pinv()
    auto A_pAA_p = A_p * A * A_p;
    for (size_t r = 0; r < A.rows(); ++r) {
        for (size_t c = 0; c < A.cols(); ++c) {
            EXPECT_NEAR(A_p(r, c), A_pAA_p(r, c), 0.001);
        }
    }

    // Check if A.pinv() * A is symmetrical
    auto ApA = A_p * A;
    ASSERT_EQ(ApA.rows(), ApA.cols()) << "A.pinv() * A is not square!";
    for (size_t i = 0; i < ApA.rows(); ++i) {
        for (size_t j = 0; j < ApA.cols(); ++j) {
            EXPECT_NEAR(ApA(i, j), ApA(j, i), 0.1);
        }
    }

    auto AAp = A * A_p;
    ASSERT_EQ(AAp.rows(), AAp.cols()) << "A * A.pinv() is not square!";
    for (size_t i = 0; i < AAp.rows(); ++i) {
        for (size_t j = 0; j < AAp.cols(); ++j) {
            EXPECT_NEAR(AAp(i, j), AAp(j, i), 0.1);
        }
    }
}

TEST(MatrixTests, RankCalculation) {
    using linalg::matrix;

    matrix<double> A(3, 3, {
        1, 2, 3,
        0, 1, 4,
        0, 0, 5
    });
    EXPECT_EQ(A.rank(), 3);

    matrix<double> B(3, 3, {
        1, 2, 3,
        2, 4, 6,
        3, 6, 9
    });
    EXPECT_EQ(B.rank(), 1);

    matrix<double> C(3, 3, {
        1, 2, 3,
        4, 5, 6,
        0, 0, 0
    });
    EXPECT_EQ(C.rank(), 2);

    matrix<double> D(4, 4, {
        1, 0, 0, 0,
        0, 1, 0, 0,
        0, 0, 1, 0,
        0, 0, 0, 1
    });
    EXPECT_EQ(D.rank(), 4);

    matrix<double> E(4, 2, {
        1, 0,
        0, 1,
        1, 1,
        2, 1
    });
    EXPECT_EQ(E.rank(), 2);

    matrix<double> F(2, 4, {
        1, 2, 3, 4,
        2, 4, 6, 8
    });
    EXPECT_EQ(F.rank(), 1);
}

TEST(MatrixTests, BasisCalculation) {
    using namespace linalg;

    matrix<double> A(3, 3, {
        1, 0, 0,
        0, 1, 0,
        0, 0, 1
    });

    auto basis_A = A.basis();
    EXPECT_EQ(basis_A.size(), 3);

    matrix<double> B(3, 3, {
        1, 2, 3,
        0, 1, 1,
        0, 0, 0
    });

    auto basis_B = B.basis();
    EXPECT_EQ(basis_B.size(), 2);

    matrix<double> C(4, 2, {
        1, 2,
        3, 4,
        5, 6,
        7, 8
    });

    auto basis_C = C.basis();
    EXPECT_EQ(basis_C.size(), 2);

    matrix<double> Z(3, 3, {
        0, 0, 0,
        0, 0, 0,
        0, 0, 0
    });

    auto basis_Z = Z.basis();
    EXPECT_EQ(basis_Z.size(), 0);
}

int main(int argc, char **argv) {
    ::testing::InitGoogleTest(&argc, argv);
    return RUN_ALL_TESTS();
}



##### ./tests/test_tenzor.cpp #####

#include <gtest/gtest.h>
#include "linalg.h"
#include <cmath>

bool floats_are_close(double a, double b, double tolerance = 0.01) {
    return std::fabs(a - b) < tolerance;
}

template<typename T, size_t N>
void assert_tensor_equal(const linalg::tensor<T, N>& result, const linalg::tensor<T, N>& expected) {
    ASSERT_EQ(result.shape(), expected.shape()) << "Shape mismatch.";

    const auto& result_data = result.get_data();
    const auto& expected_data = expected.get_data();
    ASSERT_EQ(result_data.size(), expected_data.size());

    for (size_t i = 0; i < result_data.size(); ++i) {
        EXPECT_EQ(result_data[i], expected_data[i]) << "Mismatch at index " << i;
    }
}

TEST(TensorTests, Addition) {
    linalg::tensor<int, 2> mat1({1, 2, 3, 4}, 2, 2);
    linalg::tensor<int, 2> mat2({5, 6, 7, 8}, 2, 2);
    linalg::tensor<int, 2> expected({6, 8, 10, 12}, 2, 2);

    auto result = mat1 + mat2;
    assert_tensor_equal(result, expected);
}

TEST(TensorTests, Multiplication) {
    linalg::tensor<int, 2> mat1({1, 2, 3, 4, 5, 6}, 2, 3);
    linalg::tensor<int, 2> mat2({1, 1, 1, 1, 1, 1}, 3, 2);
    linalg::tensor<int, 2> expected({6, 6, 15, 15}, 2, 2);

    auto result = mat1.multiply(mat2);
    assert_tensor_equal(result, expected);
}


##### ./CMakeLists.txt #####

cmake_minimum_required(VERSION 3.15)

set(PROJECT_NAME linear_algebra_lib)
project(${PROJECT_NAME} C CXX)

set(CMAKE_CXX_STANDARD 20)

if (NOT CMAKE_BUILD_TYPE)
	set(CMAKE_BUILD_TYPE Release)
endif()

include(FetchContent)

##########################################################
# Header-only library target
##########################################################
add_library(${PROJECT_NAME} INTERFACE)
target_include_directories(${PROJECT_NAME} INTERFACE include)

##########################################################
# Dependencies: Eigen (header-only)
##########################################################
FetchContent_Declare(
		eigen
		GIT_REPOSITORY https://gitlab.com/libeigen/eigen.git
		GIT_TAG 3.4.0
)
FetchContent_MakeAvailable(eigen)

##########################################################
# Main executables
##########################################################
add_executable(main
		src/main.cpp
)
target_link_libraries(main
		PRIVATE ${PROJECT_NAME}
)
target_include_directories(main PRIVATE ${eigen_SOURCE_DIR})

##########################################################
# Benchmark executables
##########################################################

add_executable(benchmark_runner
		benchmarks/benchmark.cpp
)
target_link_libraries(benchmark_runner
		PRIVATE ${PROJECT_NAME}
)
target_include_directories(benchmark_runner PRIVATE ${eigen_SOURCE_DIR})

add_executable(eigenvalue_benchmark
		benchmarks/eigenvalue_benchmark.cpp
)
target_link_libraries(eigenvalue_benchmark
		PRIVATE ${PROJECT_NAME}
)
target_include_directories(eigenvalue_benchmark PRIVATE ${eigen_SOURCE_DIR})

##########################################################
# GoogleTest: Unit test executable
##########################################################

FetchContent_Declare(
		gtest
		GIT_REPOSITORY https://github.com/google/googletest.git
		GIT_TAG release-1.12.1
)
FetchContent_MakeAvailable(gtest)

enable_testing()

add_executable(tests
		tests/test_vector.cpp
		tests/test_tenzor.cpp
		tests/test_matrix.cpp
		tests/test_squareMatrix.cpp
)

target_link_libraries(tests
		PRIVATE
		${PROJECT_NAME}
		gtest
		gtest_main
)

add_test(NAME unit_tests COMMAND tests)

##########################################################
# Optional: Install targets
##########################################################
install(TARGETS benchmark_runner eigenvalue_benchmark tests DESTINATION bin)


##### ./out.txt #####



##### ./src/main.cpp #####

#include <iostream>
#include "linalg.h"

int main(int argc, char* argv[]) {
    linalg::vector<linalg::vector<int>> jagged = {
        {1, 2},
        {3},
        {4, 5, 6}
    };

    linalg::matrix<int> m(jagged);

    std::cout << m.toString() << std::endl;
}


##### ./include/matrix.h #####

// This is a personal academic project. Dear PVS-Studio, please check it.
// PVS-Studio Static Code Analyzer for C, C++, C#, and Java: https://pvs-studio.com

#ifndef LINALG_MATRIX_H
#define LINALG_MATRIX_H
#include <sstream>

#include "tensor.h"

namespace linalg {
    template <typename T>
    class matrix : public tensor<T, 2> {
    protected:
        size_t rows_m, cols_m;

    public:
        matrix(const size_t rows, const size_t cols, vector<T> data = {})
            : tensor<T, 2>(data, rows, cols),
              rows_m(rows), cols_m(cols) {}

        explicit matrix(vector<vector<T>> vec2d)
            : tensor<T, 2>(
                vec2d.size(),
                vec2d.is_empty() ? 0 : std::max_element(vec2d.begin(), vec2d.end(),
                    [](const auto& a, const auto& b) {
                        return a.size() < b.size();
                    })->size()),
              rows_m(vec2d.size()),
              cols_m(vec2d.is_empty() ? 0 : std::max_element(vec2d.begin(), vec2d.end(),
                    [](const auto& a, const auto& b) {
                        return a.size() < b.size();
                    })->size())
        {
            for (size_t r = 0; r < rows_m; ++r) {
                std::copy(
                    vec2d[r].begin(),
                    vec2d[r].end(),
                    this->data_m.begin() + r * cols_m
                );

                if (vec2d[r].size() < cols_m) {
                    std::fill(
                        this->data_m.begin() + r * cols_m + vec2d[r].size(),
                        this->data_m.begin() + (r + 1) * cols_m,
                        T()
                    );
                }
            }
        }

        [[nodiscard]] size_t rows() const { return rows_m; }
        [[nodiscard]] size_t cols() const { return cols_m; }

        void reshape(const size_t rows, const size_t cols) {
            if (rows == rows_m && cols == cols_m) {
                return;
            }

            auto temp_data = vector<T>(rows * cols);

            for (size_t r = 0; r < (rows < rows_m ? rows : rows_m); r++) {
                for (size_t c = 0; c < (cols < cols_m ? cols : cols_m); c++) {
                    temp_data[r * cols + c] = this->data_m[r * cols_m + c];
                }
            }
            rows_m = rows; cols_m = cols;
            this->data_m = temp_data;
        }

        std::string toString() {
            std::stringstream ss;
            for (size_t r = 0; r < rows_m; r++) {
                for (size_t c = 0; c < cols_m; c++) {
                    ss << (*this)(r, c) << '\t';
                }
                ss << '\n';
            }

            return ss.str();
        }

        matrix<T> transpose() const{
            matrix<T> temp(cols_m, rows_m);
            for (size_t r = 0; r < rows_m; r++) {
                for (size_t c = 0; c < cols_m; c++) {
                    temp(c, r) = (*this)(r, c);
                }
            }

            return temp;
        }

        matrix<T>& operator*=(const matrix<T>& other) {
            if (this->cols_m != other.rows_m) {
                throw std::invalid_argument("Wrong dimensions of matrices");
            }

            size_t rows = this->rows_m, cols = other.cols_m;
            matrix<T> temp(rows, cols);

            for (size_t r = 0; r < rows; r++) {
                for (size_t c = 0; c < cols; c++) {
                    T sum{};
                    for (size_t i = 0; i < this->cols_m; i++) {
                        sum += (*this)(r, i) * other(i, c);
                    }
                    temp(r, c) = sum;
                }
            }
            *this = temp;
            return *this;
        }

        matrix<T>& operator*=(const T& scalar) {
            for (size_t i = 0; i < this->data_m.size(); ++i) {
                this->data_m[i] *= scalar;
            }
            return *this;
        }

        matrix<T> pinv() const;

        [[nodiscard]] size_t rank() const {
            matrix<T> temp(*this);
            const T EPS = static_cast<T>(1e-9);
            size_t rank = 0;
            size_t row = 0, col = 0;

            while (row < temp.rows_m && col < temp.cols_m) {
                // Find pivot
                size_t pivot = row;
                for (size_t i = row + 1; i < temp.rows_m; ++i) {
                    if (std::abs(temp(i, col)) > std::abs(temp(pivot, col))) {
                        pivot = i;
                    }
                }

                if (std::abs(temp(pivot, col)) < EPS) {
                    ++col;  // No pivot in this column
                    continue;
                }

                // Swap current row with pivot row
                for (size_t i = 0; i < temp.cols_m; ++i) {
                    std::swap(temp(row, i), temp(pivot, i));
                }

                // Eliminate below
                for (size_t i = row + 1; i < temp.rows_m; ++i) {
                    T factor = temp(i, col) / temp(row, col);
                    for (size_t j = col; j < temp.cols_m; ++j) {
                        temp(i, j) -= factor * temp(row, j);
                    }
                }

                ++rank;
                ++row;
                ++col;
            }

            return rank;
        }

        [[nodiscard]] vector<vector<T>> basis() const {
            matrix<T> temp(*this);
            const T EPS = static_cast<T>(1e-9);
            size_t m = temp.rows_m;
            size_t n = temp.cols_m;
            vector<size_t> pivot_columns;
            size_t row = 0;

            for (size_t col = 0; col < n && row < m; ++col) {
                size_t pivot = row;
                for (size_t i = row + 1; i < m; ++i) {
                    if (std::abs(temp(i, col)) > std::abs(temp(pivot, col))) {
                        pivot = i;
                    }
                }

                if (std::abs(temp(pivot, col)) < EPS) {
                    continue;
                }

                for (size_t j = 0; j < n; ++j) {
                    std::swap(temp(row, j), temp(pivot, j));
                }

                T pivot_val = temp(row, col);
                for (size_t j = col; j < n; ++j) {
                    temp(row, j) /= pivot_val;
                }

                for (size_t i = 0; i < m; ++i) {
                    if (i != row && std::abs(temp(i, col)) > EPS) {
                        T factor = temp(i, col);
                        for (size_t j = col; j < n; ++j) {
                            temp(i, j) -= factor * temp(row, j);
                        }
                    }
                }

                pivot_columns.push_back(col);
                ++row;
            }

            vector<vector<T>> basis_vectors;
            for (size_t col : pivot_columns) {
                vector<T> vec(m);
                for (size_t r = 0; r < m; ++r) {
                    vec[r] = (*this)(r, col);
                }
                basis_vectors.push_back(vec);
            }

            return basis_vectors;
        }

    }; // class matrix

    template <typename T>
    matrix<T> operator*(matrix<T> fst, const matrix<T>& snd) {
        fst *= snd;
        return fst;
    }

    template <typename T>
    matrix<T> operator*(matrix<T> fst, const T& snd) {
        fst *= snd;
        return fst;
    }

    template <typename T>
    matrix<T> operator*(const T& fst, matrix<T> snd) {
        snd *= fst;
        return snd;
    }

    template <typename T>
    matrix<T> operator+(const matrix<T>& lhs, const matrix<T>& rhs) {
        matrix<T> result(lhs);
        result += rhs;
        return result;
    }
} // namespace linalg

#include "squareMatrix.h"
namespace linalg{
    template <typename T>
    matrix<T> matrix<T>::pinv() const {
        auto AtA = static_cast<squareMatrix<T>>(this->transpose() * (*this));
        return AtA.inverse() * this->transpose();
    }
} // namespace linalg

#endif //LINALG_MATRIX_H


##### ./include/tensor.h #####

// This is a personal academic project. Dear PVS-Studio, please check it.
// PVS-Studio Static Code Analyzer for C, C++, C#, and Java: https://pvs-studio.com

#ifndef LINALG_NDMATRIX_H
#define LINALG_NDMATRIX_H

#include <iostream>
#include <array>
#include <stdexcept>
#include <initializer_list>
#include <cmath>

#include "vector.h"

namespace linalg {
    template <typename T, size_t N>
    class tensor {
    protected:
        vector<T> data_m;
        std::array<size_t, N> dims_m;

        size_t total_size() const {
            size_t total = 1;
            for (size_t i = 0; i < N; ++i) {
                total *= dims_m[i];
            }
            return total;
        }

        template <typename... Indices>
        size_t calculate_index(size_t iter, size_t idx, Indices... indices) const {
            size_t stride = 1;
            for (size_t i = iter + 1; i < N; ++i) {
                stride *= dims_m[i];
            }
            return idx * stride + calculate_index(iter + 1, indices...);

        }
        size_t calculate_index(size_t iter) const {
            if (iter != N) {
                throw std::invalid_argument("Number of arguments does not match dimentionality of the tensor");
            }
            return 0;
        }

    public:
        template <typename... Indices>
        explicit tensor(Indices ... indices) : data_m() {
            static_assert(sizeof...(Indices) == N, "Number of indices must match the dimension N");
            static_assert((std::is_convertible_v<Indices, size_t> && ...), "All indices must be convertible to size_t");

            dims_m = { static_cast<size_t>(indices)... };
            data_m.resize(total_size());
        }

        template <typename... Indices>
        explicit tensor(const vector<T>& data, Indices... indices)
                : tensor(indices...){
            data_m = data;
            data_m.resize(total_size());

        }

        tensor<T, N>& reshape(std::initializer_list<size_t> new_dims) {
            if (new_dims.size() != N) {
                throw std::invalid_argument("Dimension size does not match template parameter N.");
            }

            size_t new_total_size = 1;
            for (auto dim : new_dims) {
                new_total_size *= dim;
            }

            if (new_total_size != total_size()) {
                throw std::invalid_argument("New shape must have the same total size as the current shape.");
            }

            std::copy(new_dims.begin(), new_dims.end(), dims_m.begin());

            return *this;
        }

        size_t get_total_size() const {
            return total_size();
        }

        const vector<T>& get_data() const {
            return data_m;
        }

        bool operator==(const tensor<T, N>& other) const {
            for (size_t i = 0; i < data_m.size(); ++i) {
                if (data_m[i] != other.data_m[i]) {
                    return false;
                }
            }
            return true;
        }

        vector<T>& get_data() {
            return data_m;
        }

        tensor operator+= (const tensor<T, N>& other) {
            if (this->dims_m != other.dims_m) {
                throw std::invalid_argument("Matrices must have the same dimensions");
            }

            for (size_t i = 0; i < total_size(); ++i) {
                this->data_m[i] += other.data_m[i];
            }

            return *this;
        }

        tensor operator-= (const tensor<T, N>& other) {
            if (this->dims_m != other.dims_m) {
                throw std::invalid_argument("Matrices must have the same dimensions");
            }

            for (size_t i = 0; i < total_size(); ++i) {
                this->data_m[i] -= other.data_m[i];
            }

            return *this;
        }

        tensor<T, N> multiply(const tensor<T, N>& other) const {
            auto lhs_shape = this->dims_m;
            auto rhs_shape = other.dims_m;

            if (lhs_shape[1] != rhs_shape[0]) {
                throw std::invalid_argument("Incompatible dimensions for matrix multiplication.");
            }

            size_t m = lhs_shape[0];
            size_t n = rhs_shape[1];
            size_t p = lhs_shape[1];
            vector<T> result_data(m * n, 0);

            for (size_t i = 0; i < m; ++i) {
                for (size_t j = 0; j < n; ++j) {
                    for (size_t k = 0; k < p; ++k) {
                        result_data[i * n + j] += this->data_m[i * p + k] * other.data_m[k * n + j];
                    }
                }
            }

            return tensor<T, N>(result_data, m, n);
        }

        template <typename... Indices>
        T& operator()(Indices... indices) {
            static_assert(sizeof...(Indices) == N, "operator() requires exactly N indices.");
            return data_m[calculate_index(0, indices...)];
        }

        template <typename... Indices>
        const T& operator()(Indices... indices) const {
            return data_m[calculate_index(0, indices...)];
        }

        std::array<size_t, N> shape() const { return dims_m; }
    };

    template <typename T, size_t N>
    tensor<T, N> operator+ (const tensor<T, N> &fst, const tensor<T, N>& snd) {
        tensor<T, N> result(fst);
        return result += snd;
    }

    template <typename T, size_t N>
    tensor<T, N> operator- (const tensor<T, N> &fst, const tensor<T, N>& snd) {
        tensor<T, N> result(fst);
        return result -= snd;
    }
} // namespace linalg
#endif //LINALG_NDMATRIX_H


##### ./include/squareMatrix.h #####

// This is a personal academic project. Dear PVS-Studio, please check it.
// PVS-Studio Static Code Analyzer for C, C++, C#, and Java: http://www.viva64.com


#ifndef SQUAREMATRIX_H
#define SQUAREMATRIX_H

#include "matrix.h"

namespace linalg {
    template <typename T>
    class squareMatrix : public matrix<T> {
        size_t a;
    protected:
        squareMatrix<T> submatrix(size_t row, size_t col) {
            vector<T> sub_data{};
            sub_data.reserve((this->rows_m - 1) * (this->cols_m - 1));
            for (size_t r = 0; r < this->rows_m; r++) {
                if (r == row) continue;
                for (size_t c = 0; c < this->cols_m; c++) {
                    if (c == col) continue;

                    sub_data.push_back(this->data_m[r * this->cols_m + c]);
                }
            }

            return squareMatrix<T>{a-1, sub_data};
        }

        vector<T> get_column(size_t colIndex) const {
            vector<T> col(this->a);
            for (size_t i = 0; i < this->a; i++) {
                col[i] = (*this)(i, colIndex);
            }
            return col;
        }

        void set_column(size_t colIndex, const vector<T>& colData)
        {
            for (size_t i = 0; i < this->a; i++) {
                (*this)(i, colIndex) = colData[i];
            }
        }

        T offDiagonalNorm() const {
            T sum = 0;
            for (size_t i = 0; i < a; i++) {
                for (size_t j = 0; j < a; j++) {
                    if (i != j) {
                        T val = (*this)(i,j);
                        sum += val * val;
                    }
                }
            }
            return std::sqrt(sum);
        }


    public:
        explicit squareMatrix(const size_t a, vector<T> data = {}):
            matrix<T>(a, a, data), a(a) {}

        explicit squareMatrix(const matrix<T> &other)
        : matrix<T>(other),  // or matrix<T>(other.data_m, other.rows_m, other.cols_m)
          a(other.rows_m)
        {
            if (other.rows_m != other.cols_m) {
                throw std::runtime_error("Not a square matrix!");
            }
        }

        explicit squareMatrix(matrix<T>&& other)
        : matrix<T>(std::move(other)), a(other.rows())
        {
            if (other.rows() != other.cols()) {
                throw std::runtime_error("Not a square matrix!");
            }
        }

        squareMatrix& operator=(const matrix<T>& other) {
            if (other.rows() != other.cols()) {
                throw std::runtime_error("Not a square matrix!");
            }

            if (this != &other) {
                matrix<T>::operator=(other);
                a = other.rows();
            }
            return *this;
        }

        squareMatrix& operator=(matrix<T>&& other) noexcept {
            if (other.rows() != other.cols()) {
                throw std::runtime_error("Not a square matrix!");
            }

            if (this != &other) {
                matrix<T>::operator=(std::move(other));
                a = other.rows();
            }

            return *this;
        }

        static squareMatrix<T> identity(size_t n) {
            vector<T> identity_data(n * n, T{0});
            for (size_t i = 0; i < n; ++i) {
                identity_data[i * n + i] = T{1};
            }
            return squareMatrix<T>(n, identity_data);
        }

        bool isSingular() {
            return determinant() == 0;
        }

        bool isSymmetrical() {
            for (size_t r = 0; r < a; r++) {
                for (size_t c = 0; c < a; c++) {
                    if ((*this)(r, c) != (*this)(c, r))
                        return false;
                }
            }
            return true;
        }

        bool isSkewSymmetrical() {
            for (size_t r = 0; r < a; r++) {
                for (size_t c = 0; c < a; c++) {
                    if (r == c)
                        continue;

                    if ((*this)(r, c) != -(*this)(c, r))
                        return false;
                }
            }
            return true;
        }

        T minor(size_t row, size_t col) {
            squareMatrix<T> sub = submatrix(row, col);
            return sub.determinant();
        }

        T cofactor(size_t row, size_t col) {
            return (((row + col) % 2 == 0) ? 1 : -1) * minor(row, col);
        }

        T determinant() {
            if (this->rows_m == 1)
                return this->data_m[0];

            if (this->rows_m == 2)
                return this->data_m[0] * this->data_m[3] - this->data_m[1] * this->data_m[2];

            T res = 0;
            for (size_t col = 0; col < this->cols_m; ++col) {
                T cof = cofactor(0, col);
                T val = (*this)(0, col);
                res += val * cof;
            }

            return res;
        }

        std::pair<squareMatrix<T>, squareMatrix<T>> qrDecompose() const {
            squareMatrix<T> Q(a);
            squareMatrix<T> R(a);

            for (size_t i = 0; i < a; i++) {
                for (size_t j = 0; j < a; j++) {
                    Q(i, j) = 0;
                    R(i, j) = 0;
                }
            }

            for (size_t k = 0; k < a; k++) {
                vector<T> vk = this->get_column(k);

                for (size_t j = 0; j < k; j++) {
                    vector<T> qj = Q.get_column(j);
                    T rjk = 0;
                    for (size_t i = 0; i < a; i++) {
                        rjk += qj[i] * vk[i];
                    }
                    R(j, k) = rjk;
                    for (size_t i = 0; i < a; i++) {
                        vk[i] -= rjk * qj[i];
                    }
                }

                T norm = vectorNorm(vk);
                if (norm < 1e-15) {
                    R(k, k) = 0;
                    for (size_t i = 0; i < a; i++) {
                        Q(i, k) = 0;
                    }
                } else {
                    R(k, k) = norm;
                    for (size_t i = 0; i < a; i++) {
                        Q(i, k) = vk[i] / norm;
                    }
                }
            }

            return {Q, R};
        }

        vector<T> eigenvalues(double tol = 1e-9, int maxIter = 1000) const {
            squareMatrix<T> A(*this);

            int iter = 0;
            while (iter < maxIter) {
                auto [Q, R] = A.qrDecompose();

                tensor<T, 2> multiplied = R.multiply(Q);
                A = squareMatrix<T>(A.a, multiplied.get_data());

                if (A.offDiagonalNorm() < tol) {
                    break;
                }
                iter++;
            }

            vector<T> eigvals(A.a);
            for (size_t i = 0; i < A.a; i++) {
                eigvals[i] = A(i, i);
            }
            return eigvals;
        }

        vector<T> nullSpace(double tol) const {
            squareMatrix<T> A = *this;
            size_t n = this->a;

            for (size_t i = 0; i < n; ++i) {
                size_t pivotRow = i;
                for (size_t j = i + 1; j < n; ++j) {
                    if (std::abs(A(j, i)) > std::abs(A(pivotRow, i))) {
                        pivotRow = j;
                    }
                }

                if (std::abs(A(pivotRow, i)) < tol) continue;

                if (pivotRow != i) {
                    for (size_t k = 0; k < n; ++k) std::swap(A(i, k), A(pivotRow, k));
                }

                for (size_t j = i + 1; j < n; ++j) {
                    T factor = A(j, i) / A(i, i);
                    for (size_t k = i; k < n; ++k) {
                        A(j, k) -= factor * A(i, k);
                    }
                }
            }

            vector<T> x(n, 0);
            x[n - 1] = 1;

            for (int i = static_cast<int>(n) - 2; i >= 0; --i) {
                T sum = 0;
                for (size_t j = i + 1; j < n; ++j) {
                    sum += A(i, j) * x[j];
                }
                if (std::abs(A(i, i)) < tol) {
                    x[i] = 1;
                } else {
                    x[i] = -sum / A(i, i);
                }
            }

            return x;
        }

        squareMatrix<T> eigenvectorsViaNullspace(double tol = 1e-9) const {
            vector<T> eigenvals = this->eigenvalues();
            vector<vector<T>> vecs;

            for (const T& lambda : eigenvals) {
                squareMatrix<T> shifted = *this;
                for (size_t i = 0; i < this->a; ++i) {
                    shifted(i, i) -= lambda;
                }

                vector<T> v = shifted.nullSpace(tol);

                if (vectorNorm(v) > tol) {
                    for (auto& x : v) x /= vectorNorm(v);
                    vecs.push_back(v);
                } else {
                    vecs.push_back(vector<T>(this->a, 0));
                }
            }

            squareMatrix<T> result(this->a);
            for (size_t col = 0; col < vecs.size(); ++col) {
                for (size_t row = 0; row < this->a; ++row) {
                    result(row, col) = vecs[col][row];
                }
            }

            return result;
        }


        squareMatrix<T> inverse() {
            T det = this->determinant();
            if (std::abs(det) < 1e-12) {
                throw std::runtime_error("Matrix is singular or nearly singular — cannot invert.");
            }

            vector<T> cofactors_data(this->rows_m * this->cols_m);

            for (size_t r = 0; r < this->rows_m; r++) {
                for (size_t c = 0; c < this->cols_m; c++) {
                    cofactors_data[r * this->cols_m + c] = this->cofactor(r, c);
                }
            }

            squareMatrix<T> cofactorMat(this->rows_m, cofactors_data);

            squareMatrix<T> adjugate(this->rows_m);
            for (size_t i = 0; i < this->rows_m; ++i) {
                for (size_t j = 0; j < this->cols_m; ++j) {
                    adjugate(i, j) = cofactorMat(j, i);
                }
            }

            for (auto& val : adjugate.data_m) {
                val /= det;
            }

            return adjugate;
        }

        std::pair<squareMatrix<T>, squareMatrix<T>> luDecompose() const {
            if (this->a != this->rows_m || this->a != this->cols_m) {
                throw std::runtime_error("LU decomposition only valid for square matrices");
            }

            squareMatrix<T> L(this->a);
            squareMatrix<T> U(this->a);

            for (size_t i = 0; i < this->a; i++) {
                // Fill U
                for (size_t j = i; j < this->a; j++) {
                    T sum = 0;
                    for (size_t k = 0; k < i; k++) {
                        sum += L(i, k) * U(k, j);
                    }
                    U(i, j) = (*this)(i, j) - sum;
                }

                // Fill L
                for (size_t j = i; j < this->a; j++) {
                    if (i == j) {
                        L(i, i) = 1;
                    } else {
                        T sum = 0;
                        for (size_t k = 0; k < i; k++) {
                            sum += L(j, k) * U(k, i);
                        }
                        L(j, i) = ((*this)(j, i) - sum) / U(i, i);
                    }
                }
            }

            return std::make_pair(L, U);
        }

        vector<T> solve(const vector<T>& b) const {
            if (b.size() != this->a) {
                throw std::runtime_error("Size of b must match matrix dimensions.");
            }

            auto [L, U] = this->luDecompose();

            vector<T> y(this->a);
            for (size_t i = 0; i < this->a; ++i) {
                T sum = 0;
                for (size_t j = 0; j < i; ++j) {
                    sum += L(i, j) * y[j];
                }
                y[i] = b[i] - sum;
            }

            vector<T> x(this->a);
            for (int i = static_cast<int>(this->a) - 1; i >= 0; --i) {
                T sum = 0;
                for (size_t j = i + 1; j < this->a; ++j) {
                    sum += U(i, j) * x[j];
                }
                x[i] = (y[i] - sum) / U(i, i);
            }

            return x;
        }

        vector<vector<T>> eigenvectorsViaSolving(vector<T> eigenvalues, double tol = 1e-9) const {
            vector<vector<T>> eigenvectors;

            for (T lambda : eigenvalues) {
                // Form A - lambda * I
                squareMatrix<T> shifted = *this;
                for (size_t i = 0; i < this->a; ++i) {
                    shifted(i, i) -= lambda;
                }

                // We'll try to find x such that (A - λI)x = 0
                // Let’s feed a random b and normalize the result
                vector<T> b(this->a, 1.0); // or random vector, if you prefer
                vector<T> x;

                try {
                    x = shifted.solve(b);  // Will fail if matrix is singular
                } catch (...) {
                    // Matrix likely singular => try alternate approach
                    x = vector<T>(this->a, 0);
                }

                // Normalize eigenvector
                T norm = vectorNorm(x);
                if (norm > tol) {
                    for (T& val : x) val /= norm;
                    eigenvectors.push_back(x);
                }
            }

            return eigenvectors;
        }
    };

    template <typename T>
    squareMatrix<T> operator+(matrix<T> lhs, const matrix<T>& rhs) {
        lhs += rhs;
        return lhs;
    }
} // namespace linalg

#endif //SQUAREMATRIX_H


##### ./include/vector.h #####

// This is a personal academic project. Dear PVS-Studio, please check it.
// PVS-Studio Static Code Analyzer for C, C++, C#, and Java: https://pvs-studio.com

#ifndef LINALG_VECTOR_H
#define LINALG_VECTOR_H

#include <cmath>
#include <algorithm>
#include <stdexcept>
#include <iterator>
#include <initializer_list>
#include <compare>

namespace linalg {
    template<typename T>
    class vector {
    private:
        T* data_;
        size_t size_;
        size_t capacity_;

    public:
        using value_type = T;

        vector() noexcept
            : data_(nullptr), size_(0), capacity_(0) {}

        vector(size_t count, const T& value)
            : data_(nullptr), size_(0), capacity_(0) {
            reserve(count);
            for (size_t i = 0; i < count; ++i)
                new (&data_[i]) T(value);
            size_ = count;
        }

        explicit vector(size_t len)
        : data_(nullptr), size_(0), capacity_(0) {
            reserve(len);
            for (size_t i = 0; i < len; ++i)
                new (&data_[i]) T();
            size_ = len;
        }

        template<typename InputIt>
        vector(InputIt first, InputIt last)
            : data_(nullptr), size_(0), capacity_(0) {
            size_t count = std::distance(first, last);
            reserve(count);
            std::copy(first, last, data_);
            size_ = count;
        }

        vector(std::initializer_list<T> init)
        : data_(static_cast<T*>(::operator new(init.size() * sizeof(T)))),
          size_(init.size()),
          capacity_(init.size())
        {
            size_t i = 0;
            try {
                for (const auto& item : init) {
                    new (&data_[i++]) T(item);
                }
            } catch (...) {
                for (size_t j = 0; j < i; ++j) {
                    data_[j].~T();
                }
                ::operator delete(data_);
                throw;
            }
        }

        vector(const vector& other)
        : data_(static_cast<T*>(::operator new(other.capacity_ * sizeof(T)))),
          size_(other.size_),
          capacity_(other.capacity_)
        {
            for (size_t i = 0; i < size_; ++i) {
                new (&data_[i]) T(other.data_[i]);  // deep copy each element
            }
        }

        vector(vector&& other) noexcept
            : data_(other.data_),
              size_(other.size_),
              capacity_(other.capacity_)
        {
            other.data_ = nullptr;
            other.size_ = 0;
            other.capacity_ = 0;
        }

        ~vector() {
            clear();  // Explicitly destroys all elements
            ::operator delete(data_);  // Raw memory deallocation without calling destructors
        }

        vector& operator=(const vector& other) {
            if (this != &other) {
                vector temp(other);
                swap(temp);
            }
            return *this;
        }

        vector& operator=(vector&& other) noexcept {
            if (this != &other) {
                clear();
                ::operator delete(data_);
                data_ = other.data_;
                size_ = other.size_;
                capacity_ = other.capacity_;
                other.data_ = nullptr;
                other.size_ = other.capacity_ = 0;
            }
            return *this;
        }

        T& operator[](size_t index) noexcept { return data_[index]; }
        const T& operator[](size_t index) const noexcept { return data_[index]; }

        T& at(size_t index) {
            if (index >= size_) throw std::out_of_range("vector::at");
            return data_[index];
        }
        const T& at(size_t index) const {
            if (index >= size_) throw std::out_of_range("vector::at");
            return data_[index];
        }

        T& front() {
            if (is_empty()) throw std::out_of_range("vector::front");
            return data_[0];
        }
        const T& front() const {
            if (is_empty()) throw std::out_of_range("vector::front");
            return data_[0];
        }

        T& back() {
            if (is_empty()) throw std::out_of_range("vector::back");
            return data_[size_ - 1];
        }
        const T& back() const {
            if (is_empty()) throw std::out_of_range("vector::back");
            return data_[size_ - 1];
        }

        T* begin() noexcept { return data_; }
        T* end() noexcept { return data_ + size_; }
        const T* begin() const noexcept { return data_; }
        const T* end() const noexcept { return data_ + size_; }
        const T* cbegin() const noexcept { return data_; }
        const T* cend() const noexcept { return data_ + size_; }

        auto rbegin() noexcept { return std::reverse_iterator<T*>(end()); }
        auto rend() noexcept { return std::reverse_iterator<T*>(begin()); }
        auto rbegin() const noexcept { return std::reverse_iterator<const T*>(end()); }
        auto rend() const noexcept { return std::reverse_iterator<const T*>(begin()); }
        auto rcbegin() const noexcept { return rbegin(); }
        auto rcend() const noexcept { return rend(); }

        bool is_empty() const noexcept { return size_ == 0; }
        size_t size() const noexcept { return size_; }
        size_t capacity() const noexcept { return capacity_; }

        void reserve(size_t new_cap) {
            if (new_cap <= capacity_) return;

            T* new_data = static_cast<T*>(::operator new(new_cap * sizeof(T)));

            for (size_t i = 0; i < size_; ++i) {
                new (&new_data[i]) T(std::move_if_noexcept(data_[i]));
                data_[i].~T();
            }

            ::operator delete(data_);
            data_ = new_data;
            capacity_ = new_cap;
        }

        void shrink_to_fit() {
            if (size_ < capacity_) {
                T* new_data = nullptr;
                if (size_) {
                    new_data = static_cast<T*>(::operator new(size_ * sizeof(T)));
                    for (size_t i = 0; i < size_; ++i) {
                        new (&new_data[i]) T(std::move_if_noexcept(data_[i]));
                        data_[i].~T();
                    }
                }
                ::operator delete(data_);
                data_ = new_data;
                capacity_ = size_;
            }
        }

        void clear() noexcept {
            for (size_t i = 0; i < size_; ++i)
                data_[i].~T();
            size_ = 0;
        }

        void resize(size_t count, const T& value = T()) {
            if (count < size_) {
                for (size_t i = count; i < size_; ++i)
                    data_[i].~T();
            } else if (count > size_) {
                reserve(count);
                for (size_t i = size_; i < count; ++i)
                    new (&data_[i]) T(value);
            }
            size_ = count;
        }

        void swap(vector& other) noexcept {
            std::swap(data_, other.data_);
            std::swap(size_, other.size_);
            std::swap(capacity_, other.capacity_);
        }

        T* insert(T* pos, const T& value) {
            size_t idx = pos - data_;
            if (pos < data_ || pos > end()) throw std::out_of_range("insert");
            if (size_ == capacity_) reserve(capacity_ ? capacity_ * 2 : 1);
            pos = data_ + idx;
            for (size_t i = size_; i > idx; --i) {
                new (&data_[i]) T(std::move_if_noexcept(data_[i - 1]));
                data_[i - 1].~T();
            }
            new (&data_[idx]) T(value);
            ++size_;
            return data_ + idx;
        }

        template<typename InputIt>
        T* insert(T* pos, InputIt first, InputIt last) {
            size_t idx = pos - data_;
            size_t count = std::distance(first, last);
            if (pos < data_ || pos > end()) throw std::out_of_range("insert range");
            if (size_ + count > capacity_) reserve(std::max(capacity_ * 2, size_ + count));
            pos = data_ + idx;
            for (size_t i = size_; i > idx; --i) {
                new (&data_[i + count - 1]) T(std::move_if_noexcept(data_[i - 1]));
                data_[i - 1].~T();
            }
            for (size_t i = 0; i < count; ++i)
                new (&data_[idx + i]) T(*std::next(first, i));
            size_ += count;
            return data_ + idx;
        }

        T* erase(T* pos) {
            if (pos < data_ || pos >= end()) throw std::out_of_range("erase");
            size_t idx = pos - data_;
            data_[idx].~T();
            for (size_t i = idx; i < size_ - 1; ++i) {
                new (&data_[i]) T(std::move_if_noexcept(data_[i + 1]));
                data_[i + 1].~T();
            }
            --size_;
            return data_ + idx;
        }

        T* erase(T* first, T* last) {
            if (first < data_ || last > end() || first > last) throw std::out_of_range("erase range");
            size_t idx = first - data_;
            size_t count = last - first;
            for (size_t i = 0; i < count; ++i)
                data_[idx + i].~T();
            for (size_t i = idx + count; i < size_; ++i) {
                new (&data_[i - count]) T(std::move_if_noexcept(data_[i]));
                data_[i].~T();
            }
            size_ -= count;
            return data_ + idx;
        }

        void push_back(const T& value) {
            if (size_ == capacity_) {
                // handle self reference
                T value_copy = value;
                reserve(capacity_ ? capacity_ * 2 : 1);
                new (&data_[size_++]) T(std::move(value_copy));
            } else {
                new (&data_[size_++]) T(value);
            }
        }

        void concat(const vector<T>& v2) {
            reserve(this->size() + v2.size());
            std::copy(v2.begin(), v2.end(), std::back_inserter(*this));
        }

        void pop_back() {
            if (is_empty()) throw std::out_of_range("pop_back");
            data_[--size_ - 1].~T();
        }

        template<typename... Args>
        void emplace_back(Args&&... args) {
            if (size_ == capacity_)
                reserve(capacity_ ? capacity_ * 2 : 1);
            new (&data_[size_++]) T(std::forward<Args>(args)...);
        }

        auto operator<=>(const vector& other) const {
            return std::lexicographical_compare_three_way(
                begin(), end(), other.begin(), other.end());
        }

        bool operator==(const vector& other) const {
            if (size_ != other.size_) return false;
            for (size_t i = 0; i < size_; ++i)
                if (!(data_[i] == other.data_[i]))
                    return false;
            return true;
        }
    };

    template<typename T>
    T vectorNorm(const vector<T>& v) {
        T sum = 0;
        for (auto &val : v) sum += val * val;
        return std::sqrt(sum);
    }
} // namespace linalg

#endif //LINALG_VECTOR_H


##### ./include/linalg.h #####

// This is a personal academic project. Dear PVS-Studio, please check it.
// PVS-Studio Static Code Analyzer for C, C++, C#, and Java: https://pvs-studio.com

#ifndef LINALG_H
#define LINALG_H

#include "vector.h"
#include "tensor.h"
#include "matrix.h"
#include "squareMatrix.h"

#endif // LINALG_H


##### ./benchmarks/benchmark.cpp #####

#include <iostream>
#include <chrono>
#include <fstream>
#include <vector>
#include <Eigen/Dense>
#include "matrix.h"

using namespace std::chrono;

// Generic benchmarking function (in milliseconds)
template <typename Func>
double benchmark(Func func, int repetitions = 10) {
    double total_time = 0.0;
    for (int i = 0; i < repetitions; ++i) {
        auto start = high_resolution_clock::now();
        func();
        auto end = high_resolution_clock::now();
        total_time += duration<double, std::milli>(end - start).count();
    }
    return total_time / repetitions;
}

void run_addition_benchmark(std::ofstream& file, int size, int repetitions) {
    linalg::matrix<float> my_a(size, size), my_b(size, size);
    for (size_t i = 0; i < my_a.get_total_size(); ++i) {
        my_a.get_data()[i] = 1.0f;
        my_b.get_data()[i] = 2.0f;
    }

    Eigen::MatrixXf eigen_a = Eigen::MatrixXf::Constant(size, size, 1.0f);
    Eigen::MatrixXf eigen_b = Eigen::MatrixXf::Constant(size, size, 2.0f);

    double mylib_time = benchmark([&]() {
        linalg::matrix<float> c(my_a);
        c += my_b;
    }, repetitions);

    double eigen_time = benchmark([&]() {
        Eigen::MatrixXf c = eigen_a + eigen_b;
    }, repetitions);

    file << size << "," << mylib_time << "," << eigen_time << "\n";
}

void run_multiplication_benchmark(std::ofstream& file, int size, int repetitions) {
    linalg::matrix<float> my_a(size, size), my_b(size, size);
    for (size_t i = 0; i < my_a.get_total_size(); ++i) {
        my_a.get_data()[i] = 1.0f;
        my_b.get_data()[i] = 1.0f;
    }

    Eigen::MatrixXf eigen_a = Eigen::MatrixXf::Constant(size, size, 1.0f);
    Eigen::MatrixXf eigen_b = Eigen::MatrixXf::Constant(size, size, 1.0f);

    double mylib_time = benchmark([&]() {
        linalg::matrix<float> c = my_a * my_b;
    }, repetitions);

    double eigen_time = benchmark([&]() {
        Eigen::MatrixXf c = eigen_a * eigen_b;
    }, repetitions);

    file << size << "," << mylib_time << "," << eigen_time << "\n";
}

int main() {
    std::ofstream add_file("addition_results.csv");
    std::ofstream mult_file("multiplication_results.csv");

    add_file << "Size,YourMatrix(ms),Eigen(ms)\n";
    mult_file << "Size,YourMatrix(ms),Eigen(ms)\n";

    int repetitions = 10;

    for (int size = 100; size <= 1000; size += 100) {
        std::cout << "Running benchmarks for size: " << size << "...\n";
        run_addition_benchmark(add_file, size, repetitions);
        run_multiplication_benchmark(mult_file, size, repetitions);
    }

    add_file.close();
    mult_file.close();

    std::cout << "Benchmarks completed. Results saved to CSV files.\n";
    return 0;
}


##### ./benchmarks/eigenvalue_benchmark.cpp #####

#include <iostream>
#include <chrono>
#include <fstream>
#include "linalg.h"
#include <cmath>
#include <random>
#include <Eigen/Dense>
#include "squareMatrix.h"

using namespace std;
using namespace std::chrono;

template<typename Func>
double benchmark(Func func, int repetitions = 10) {
    double total_time = 0.0;
    for (int i = 0; i < repetitions; ++i) {
        auto start = high_resolution_clock::now();
        func();
        auto end = high_resolution_clock::now();
        total_time += duration<double, std::milli>(end - start).count(); // milliseconds
    }
    return total_time / repetitions;
}

// Generate symmetric matrix of size n x n
linalg::squareMatrix<double> generate_symmetric_matrix(size_t n) {
    linalg::vector<double> data(n * n, 0);
    std::mt19937 gen(random_device{}());
    std::uniform_real_distribution<> dis(-10.0, 10.0);

    for (size_t i = 0; i < n; ++i) {
        for (size_t j = i; j < n; ++j) {
            double val = dis(gen);
            data[i * n + j] = val;
            data[j * n + i] = val;
        }
    }

    return linalg::squareMatrix<double>(n, data);
}

void run_benchmark(const std::string& output_csv, int min_size = 5, int max_size = 75, int step = 5, int repetitions = 10) {
    ofstream file(output_csv);
    file << "Size,YourMatrix(ms),Eigen(ms)\n";

    for (int size = min_size; size <= max_size; size += step) {
        cout << "Benchmarking size: " << size << "..." << endl;

        double total_your_time = 0;
        double total_eigen_time = 0;

        for (int rep = 0; rep < repetitions; ++rep) {
            linalg::squareMatrix<double> my_mat = generate_symmetric_matrix(size);

            // Copy to Eigen
            Eigen::MatrixXd eigen_mat(size, size);
            for (int r = 0; r < size; ++r)
                for (int c = 0; c < size; ++c)
                    eigen_mat(r, c) = my_mat(r, c);

            // Your lib
            total_your_time += benchmark([&]() {
                volatile auto eigvals = my_mat.eigenvalues();
            }, 1); // 1 rep here since outer loop controls it

            // Eigen
            total_eigen_time += benchmark([&]() {
                Eigen::EigenSolver<Eigen::MatrixXd> solver(eigen_mat);
                volatile auto eigvals = solver.eigenvalues();
            }, 1);
        }

        double avg_your_time = total_your_time / repetitions;
        double avg_eigen_time = total_eigen_time / repetitions;

        file << size << "," << avg_your_time << "," << avg_eigen_time << "\n";
    }

    file.close();
    cout << "Benchmark complete! Results saved to: " << output_csv << endl;
}

int main() {
    run_benchmark("eigenvalue_benchmark.csv");
    return 0;
}


##### ./tests/test_vector.cpp #####

#include <gtest/gtest.h>
#include "linalg.h"
#include <stdexcept>
#include <initializer_list>
#include <iterator>
#include <algorithm>
#include <string>

TEST(vector, DefaultConstructor) {
    linalg::vector<int> v;
    EXPECT_TRUE(v.is_empty());
    EXPECT_EQ(v.size(), 0);
}

TEST(vector, FillConstructor) {
    linalg::vector<int> v(static_cast<size_t>(5), 42);
    EXPECT_EQ(v.size(), 5);
    for (int i = 0; i < 5; ++i)
        EXPECT_EQ(v[i], 42);
}

TEST(vector, IteratorConstructor) {
    std::vector<int> source = {1, 2, 3, 4};
    linalg::vector<int> v(source.begin(), source.end());
    EXPECT_EQ(v.size(), 4);
    EXPECT_EQ(v[2], 3);
}

TEST(vector, InitializerListConstructor) {
    linalg::vector<std::string> v{"a", "b", "c"};
    EXPECT_EQ(v.size(), 3);
    EXPECT_EQ(v[0], "a");
    EXPECT_EQ(v[1], "b");
    EXPECT_EQ(v[2], "c");
}

TEST(vector, CopyConstructor) {
    linalg::vector<int> v1{1, 2, 3};
    linalg::vector<int> v2 = v1;
    EXPECT_EQ(v2, v1);
}

TEST(vector, MoveConstructor) {
    linalg::vector<int> temp{5, 6};
    linalg::vector<int> v = std::move(temp);
    EXPECT_EQ(v.size(), 2);
    EXPECT_EQ(v[0], 5);
    EXPECT_EQ(v[1], 6);
}

TEST(vector, CopyAssignment) {
    linalg::vector<int> a{1, 2, 3};
    linalg::vector<int> b;
    b = a;
    EXPECT_EQ(a, b);
}

TEST(vector, MoveAssignment) {
    linalg::vector<int> a{1, 2};
    linalg::vector<int> b;
    b = std::move(a);
    EXPECT_EQ(b.size(), 2);
    EXPECT_EQ(b[0], 1);
    EXPECT_EQ(b[1], 2);
}

TEST(vector, IndexOperator) {
    linalg::vector<char> v{'a', 'b'};
    EXPECT_EQ(v[1], 'b');
}

TEST(vector, AtThrowsOutOfBounds) {
    linalg::vector<int> v{1, 2, 3};
    EXPECT_THROW(v.at(10), std::out_of_range);
}

TEST(vector, FrontBack) {
    linalg::vector<int> v{10, 20, 30};
    EXPECT_EQ(v.front(), 10);
    EXPECT_EQ(v.back(), 30);
}

TEST(vector, Iterators) {
    linalg::vector<int> v{1, 2, 3};
    auto it = std::find(v.begin(), v.end(), 2);
    EXPECT_NE(it, v.end());
    EXPECT_EQ(*it, 2);
}

TEST(vector, BackInserterCompatibility) {
    linalg::vector<int> v;
    std::vector<int> source = {1, 2, 3};
    std::copy(source.begin(), source.end(), std::back_inserter(v));
    EXPECT_EQ(v.size(), 3);
    EXPECT_EQ(v.back(), 3);
}

TEST(vector, CapacityManagement) {
    linalg::vector<int> v;
    v.reserve(10);
    EXPECT_GE(v.capacity(), 10);
    v.shrink_to_fit();
    EXPECT_LE(v.capacity(), 10);
}

TEST(vector, ResizeAndClear) {
    linalg::vector<int> v{1, 2, 3};
    v.resize(5);
    EXPECT_EQ(v.size(), 5);
    v.clear();
    EXPECT_TRUE(v.is_empty());
}

TEST(vector, ResizeShrink) {
    linalg::vector<int> v{1, 2, 3, 4, 5};
    v.resize(3);
    EXPECT_EQ(v.size(), 3);
    EXPECT_EQ(v[0], 1);
    EXPECT_EQ(v[2], 3);
}

TEST(vector, ResizeGrowDefault) {
    linalg::vector<int> v{1, 2};
    v.resize(5);
    EXPECT_EQ(v.size(), 5);
    EXPECT_EQ(v[2], {});
}

TEST(vector, InsertSingle) {
    linalg::vector<int> v{1, 3};
    auto it = v.insert(v.begin() + 1, 2);
    EXPECT_EQ(*it, 2);
    EXPECT_EQ(v[1], 2);
}

TEST(vector, InsertAtBeginEmpty) {
    linalg::vector<int> v;
    v.insert(v.begin(), 42);
    EXPECT_EQ(v.size(), 1);
    EXPECT_EQ(v[0], 42);
}

TEST(vector, InsertAtEnd) {
    linalg::vector<int> v{1, 2, 3};
    v.insert(v.end(), 4);
    EXPECT_EQ(v.size(), 4);
    EXPECT_EQ(v[3], 4);
}

TEST(vector, InsertRange) {
    linalg::vector<int> v{1, 5};
    std::vector<int> to_insert{2, 3, 4};
    v.insert(v.begin() + 1, to_insert.begin(), to_insert.end());
    EXPECT_EQ(v[2], 3);
}

TEST(vector, EraseSingle) {
    linalg::vector<int> v{1, 2, 3};
    auto it = v.erase(v.begin() + 1);
    EXPECT_EQ(*it, 3);
    EXPECT_EQ(v.size(), 2);
}

TEST(vector, EraseRange) {
    linalg::vector<int> v{1, 2, 3, 4, 5};
    auto it = v.erase(v.begin() + 1, v.begin() + 4);
    EXPECT_EQ(*it, 5);
    EXPECT_EQ(v.size(), 2);
}

TEST(vector, EraseFromEmpty) {
    linalg::vector<int> v;
    EXPECT_THROW(v.erase(v.begin()), std::out_of_range);
}

TEST(vector, PushPopEmplaceBack) {
    linalg::vector<std::string> v;
    v.push_back("hi");
    v.emplace_back("there");
    EXPECT_EQ(v.size(), 2);
    EXPECT_EQ(v.back(), "there");
    v.pop_back();
    EXPECT_EQ(v.size(), 1);
}

TEST(vector, ComparisonOperators) {
    linalg::vector<int> a{1, 2, 3};
    linalg::vector<int> b{1, 2, 4};
    EXPECT_TRUE(a < b);
    EXPECT_TRUE(a != b);
    EXPECT_FALSE(a == b);
}

TEST(vector, SwapMethod) {
    linalg::vector<int> a{1, 2}, b{3, 4};
    a.swap(b);
    EXPECT_EQ(a[0], 3);
    EXPECT_EQ(b[0], 1);
}

TEST(vector, SwapWithEmptyVector) {
    linalg::vector<int> v1{1, 2, 3};
    linalg::vector<int> v2;
    v1.swap(v2);
    EXPECT_EQ(v1.size(), 0);
    EXPECT_EQ(v2.size(), 3);
    EXPECT_EQ(v2[0], 1);
}

TEST(vector, NestedVectorsBasic) {
    linalg::vector<linalg::vector<int>> vv;
    linalg::vector<int> inner1 = {1, 2, 3};
    linalg::vector<int> inner2 = {4, 5};

    vv.push_back(inner1);
    vv.push_back(inner2);

    ASSERT_EQ(vv.size(), 2);
    EXPECT_EQ(vv[0].size(), 3);
    EXPECT_EQ(vv[1][1], 5);
}

TEST(vector, NestedVectorsEmplaceBack) {
    linalg::vector<linalg::vector<int>> vv;
    vv.emplace_back(linalg::vector<int>{1, 2});
    vv.emplace_back(linalg::vector<int>{3, 4});

    EXPECT_EQ(vv.size(), 2);
    EXPECT_EQ(vv[0].front(), 1);
    EXPECT_EQ(vv[1].back(), 4);
}

TEST(vector, PushBackSelfBack) {
    linalg::vector<int> v;
    for (int i = 0; i < 10; ++i) {
        v.push_back(i);
    }

    int last = v.back();
    v.push_back(last);

    EXPECT_EQ(v.size(), 11);
    EXPECT_EQ(v.back(), 9);
}

TEST(vector, NestedPushBackSelfBack) {
    linalg::vector<linalg::vector<int>> v;
    linalg::vector<int> tmp = {1, 2};
    v.push_back(tmp);
    v.push_back(v.back()); // Copy of the last vector

    ASSERT_EQ(v.size(), 2);
    EXPECT_EQ(v[1], v[0]); // Must be deep copy
}



##### ./tests/test_squareMatrix.cpp #####

#include <gtest/gtest.h>
#include "linalg.h"

TEST(SquareMatrixTests, Inverse) {
    linalg::squareMatrix<double> A(2, {4, 7, 2, 6});
    auto Ainv = A.inverse();
    auto result = A.multiply(Ainv);
    auto expected = linalg::squareMatrix<double>::identity(2);

    const auto& res_data = result.get_data();
    const auto& exp_data = expected.get_data();

    for (size_t i = 0; i < res_data.size(); ++i) {
        EXPECT_NEAR(res_data[i], exp_data[i], 1e-6);
    }
}

TEST(SquareMatrixTests, LUDecomposition) {
    linalg::squareMatrix<double> A(2, {4, 3, 6, 3});
    auto [L, U] = A.luDecompose();
    auto recomposed = L.multiply(U);

    const auto& orig = A.get_data();
    const auto& recomposed_data = recomposed.get_data();
    for (size_t i = 0; i < orig.size(); ++i) {
        EXPECT_NEAR(orig[i], recomposed_data[i], 1e-6);
    }
}

TEST(SquareMatrixTests, SolveEquation) {
    linalg::squareMatrix<double> A(2, {2, 1, 5, 7});
    linalg::vector<double> b = {11, 13};
    linalg::vector<double> expected_x = {7.1111, -3.2222};

    auto x = A.solve(b);

    ASSERT_EQ(x.size(), expected_x.size());
    for (size_t i = 0; i < x.size(); ++i) {
        EXPECT_NEAR(x[i], expected_x[i], 0.01);
    }
}

##### ./tests/test_matrix.cpp #####

#include <gtest/gtest.h>
#include "linalg.h"
#include <cmath>


TEST(MatrixConstructorTest, ColumnVectorInitialization) {
    linalg::vector<linalg::vector<int>> data = {
        {1, 2, 3},
        {4, 5, 6},
        {7, 8, 9}
    };

    linalg::matrix<int> m(data);

    EXPECT_EQ(m.cols(), 3);
    EXPECT_EQ(m.rows(), 3);

    EXPECT_EQ(m(0, 0), 1);
    EXPECT_EQ(m(0, 1), 2);
    EXPECT_EQ(m(0, 2), 3);
    EXPECT_EQ(m(1, 0), 4);
    EXPECT_EQ(m(1, 1), 5);
    EXPECT_EQ(m(1, 2), 6);
    EXPECT_EQ(m(2, 0), 7);
    EXPECT_EQ(m(2, 1), 8);
    EXPECT_EQ(m(2, 2), 9);
}

TEST(MatrixConstructorTest, HandlesEmptyColumnVector) {
    linalg::vector<linalg::vector<int>> empty_data;
    linalg::matrix<int> m(empty_data);

    EXPECT_EQ(m.cols(), 0);
    EXPECT_EQ(m.rows(), 0);
}

TEST(MatrixConstructorTest, PadsShortRows) {
    linalg::vector<linalg::vector<int>> jagged = {
        {1, 2},
        {3},
        {4, 5, 6}
    };

    linalg::matrix<int> m(jagged);

    EXPECT_EQ(m.cols(), 3);
    EXPECT_EQ(m.rows(), 3);

    EXPECT_EQ(m(0, 0), 1);
    EXPECT_EQ(m(0, 1), 2);
    EXPECT_EQ(m(0, 2), {});

    EXPECT_EQ(m(1, 0), 3);
    EXPECT_EQ(m(1, 1), {});
    EXPECT_EQ(m(1, 2), {});

    EXPECT_EQ(m(2, 0), 4);
    EXPECT_EQ(m(2, 1), 5);
    EXPECT_EQ(m(2, 2), 6);
}


TEST(MatrixTests, EigenvaluesAndVectors) {
    linalg::vector<double> data = {
        5, 10, -5,
        2, -14, 2,
        -4, -8, 6
    };
    linalg::squareMatrix<double> M(3, data);
    auto evals = M.eigenvalues();

    for (const auto& val : evals) {
        EXPECT_TRUE(std::isfinite(val));
    }

    auto evecs = M.eigenvectorsViaNullspace();
    EXPECT_EQ(evecs.rows(), 3);
    EXPECT_EQ(evecs.cols(), evals.size());
}

TEST(MatrixTests, PseudoInverse) {
    linalg::matrix<double> A(3, 2, {1, 2, 3, 4, 5, 6});
    auto A_p = A.pinv();

    // A * A.pinv() * A == A
    auto AA_pA = A * A_p * A;
    for (size_t r = 0; r < A.rows(); ++r) {
        for (size_t c = 0; c < A.cols(); ++c) {
            EXPECT_NEAR(A(r, c), AA_pA(r, c), 0.001);
        }
    }

    // A.pinv() * A * A.pinv() == A.pinv()
    auto A_pAA_p = A_p * A * A_p;
    for (size_t r = 0; r < A.rows(); ++r) {
        for (size_t c = 0; c < A.cols(); ++c) {
            EXPECT_NEAR(A_p(r, c), A_pAA_p(r, c), 0.001);
        }
    }

    // Check if A.pinv() * A is symmetrical
    auto ApA = A_p * A;
    ASSERT_EQ(ApA.rows(), ApA.cols()) << "A.pinv() * A is not square!";
    for (size_t i = 0; i < ApA.rows(); ++i) {
        for (size_t j = 0; j < ApA.cols(); ++j) {
            EXPECT_NEAR(ApA(i, j), ApA(j, i), 0.1);
        }
    }

    auto AAp = A * A_p;
    ASSERT_EQ(AAp.rows(), AAp.cols()) << "A * A.pinv() is not square!";
    for (size_t i = 0; i < AAp.rows(); ++i) {
        for (size_t j = 0; j < AAp.cols(); ++j) {
            EXPECT_NEAR(AAp(i, j), AAp(j, i), 0.1);
        }
    }
}

TEST(MatrixTests, RankCalculation) {
    using linalg::matrix;

    matrix<double> A(3, 3, {
        1, 2, 3,
        0, 1, 4,
        0, 0, 5
    });
    EXPECT_EQ(A.rank(), 3);

    matrix<double> B(3, 3, {
        1, 2, 3,
        2, 4, 6,
        3, 6, 9
    });
    EXPECT_EQ(B.rank(), 1);

    matrix<double> C(3, 3, {
        1, 2, 3,
        4, 5, 6,
        0, 0, 0
    });
    EXPECT_EQ(C.rank(), 2);

    matrix<double> D(4, 4, {
        1, 0, 0, 0,
        0, 1, 0, 0,
        0, 0, 1, 0,
        0, 0, 0, 1
    });
    EXPECT_EQ(D.rank(), 4);

    matrix<double> E(4, 2, {
        1, 0,
        0, 1,
        1, 1,
        2, 1
    });
    EXPECT_EQ(E.rank(), 2);

    matrix<double> F(2, 4, {
        1, 2, 3, 4,
        2, 4, 6, 8
    });
    EXPECT_EQ(F.rank(), 1);
}

TEST(MatrixTests, BasisCalculation) {
    using namespace linalg;

    matrix<double> A(3, 3, {
        1, 0, 0,
        0, 1, 0,
        0, 0, 1
    });

    auto basis_A = A.basis();
    EXPECT_EQ(basis_A.size(), 3);

    matrix<double> B(3, 3, {
        1, 2, 3,
        0, 1, 1,
        0, 0, 0
    });

    auto basis_B = B.basis();
    EXPECT_EQ(basis_B.size(), 2);

    matrix<double> C(4, 2, {
        1, 2,
        3, 4,
        5, 6,
        7, 8
    });

    auto basis_C = C.basis();
    EXPECT_EQ(basis_C.size(), 2);

    matrix<double> Z(3, 3, {
        0, 0, 0,
        0, 0, 0,
        0, 0, 0
    });

    auto basis_Z = Z.basis();
    EXPECT_EQ(basis_Z.size(), 0);
}

int main(int argc, char **argv) {
    ::testing::InitGoogleTest(&argc, argv);
    return RUN_ALL_TESTS();
}



##### ./tests/test_tenzor.cpp #####

#include <gtest/gtest.h>
#include "linalg.h"
#include <cmath>

bool floats_are_close(double a, double b, double tolerance = 0.01) {
    return std::fabs(a - b) < tolerance;
}

template<typename T, size_t N>
void assert_tensor_equal(const linalg::tensor<T, N>& result, const linalg::tensor<T, N>& expected) {
    ASSERT_EQ(result.shape(), expected.shape()) << "Shape mismatch.";

    const auto& result_data = result.get_data();
    const auto& expected_data = expected.get_data();
    ASSERT_EQ(result_data.size(), expected_data.size());

    for (size_t i = 0; i < result_dat.size(); ++i) {
        EXPECT_EQ(result_data[i], expected_data[i]) << "Mismatch at index " << i;
    }
}

TEST(TensorTests, Addition) {
    linalg::tensor<int, 2> mat1({1, 2, 3, 4}, 2, 2);
    linalg::tensor<int, 2> mat2({5, 6, 7, 8}, 2, 2);
    linalg::tensor<int, 2> expected({6, 8, 10, 12}, 2, 2);

    auto result = mat1 + mat2;
    assert_tensor_equal(result, expected);
}

TEST(TensorTests, Multiplication) {
    linalg::tensor<int, 2> mat1({1, 2, 3, 4, 5, 6}, 2, 3);
    linalg::tensor<int, 2> mat2({1, 1, 1, 1, 1, 1}, 3, 2);
    linalg::tensor<int, 2> expected({6, 6, 15, 15}, 2, 2);

    auto result = mat1.multiply(mat2);
    assert_tensor_equal(result, expected);
}
